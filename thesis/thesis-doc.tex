\documentclass[12pt]{article}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}

\input{defs.tex}

\begin{document}

\section{Type Structure}

\subsection{Syntax of Types and Kinds}

In this section, I will describe the type structure of the 
programming language I will use for this thesis. The language is a
pure, total, predicatively polymorphic programming language (with
quantification over higher kinds), augmented with a monadic type
constructor that permits nontermination, higher-order state, and
continuations. 

\todo{Add support for polynomial data types}

\begin{displaymath}
  \begin{array}{lcll}
    \mbox{Kinds} & 
      \kappa & ::= & \star \bnfalt \kappa \to \kappa 
    \\[1em]
    \mbox{Monotypes} & 
      \tau & ::= & 
         \unittype \bnfalt 
         \tau \times \tau \bnfalt 
         \tau \to \tau \bnfalt 
         \tau + \tau \bnfalt
         \N \bnfalt \\
     &&& \reftype{A} \bnfalt
         \monad{\tau} \bnfalt 
         \cont{\tau} \\
     &&& \alpha \bnfalt
         \tau\;\tau \bnfalt 
         \fun{\alpha}{\kappa}{\tau} 
    \\[1em]
    \mbox{Polytypes} & 
      A & ::= & 
         \unittype \bnfalt 
         A \times B \bnfalt 
         A + B \bnfalt
         A \to B \bnfalt 
         \N \bnfalt  \\
    &&&  \reftype{A} \bnfalt
         \monad{A} \bnfalt 
         \cont{A} \\
    &&&  \alpha \bnfalt
         \tau\;\tau \bnfalt \\
    &&&  \forall \alpha:\kappa.\; A \bnfalt 
         \exists \alpha:\kappa.\; A \\[1em]
    \mbox{Type Contexts} & 
      \Theta & ::= & \cdot \bnfalt \Theta, \alpha:\kappa \\
  \end{array}
\end{displaymath}

The basic kind structure of the language is given with the kinds
$\kappa$. The The kind $\star$ is the kind of monotypes, which are
written with the letter $\tau$. These are the unit type $\unittype$,
pair types $\tau \times \sigma$, sums $\tau + \sigma$, function space
$\tau \to \sigma$, natural numbers $\N$, computation types
$\monad{\tau}$, continuation types $\cont{\tau}$ and finally
(ML-style) references $\reftype{A}$. Also, within open types we may
also use type variables $\alpha$ to refer to types, and we can also
define lambda-abstractions and applications to inhabit the higher
kinds of this language.

The type $\reftype{A}$ is not merely a pointer to a value of
monomorphic type; instead, it also permits storing a pointer to a
value of polymorphic types $A$. The intuition justifying this
liberality is that a reference to a value of polymorphic type is
itself merely a location, so it is permissible to treat a reference to
a value of polymorphic type as a monomorphic value. Indeed, the
denotational semantics of references will rely upon this intuition.

The polytypes $A$ themselves extend the monotypes with universal
quantification $\forall \alpha:\kappa.\;A$ as well as existential
types $\exists \alpha:\kappa.\;A$. Each of the simple type
constructors -- sums, products, functions, computations -- also may
contain polymorphic types as subexpressions within it. Though it may
not look like it at first glance, this is actually only a fairly modest
generalization of the type schemes of ML. Because the universal and
existential quantifiers range over the kinds $\kappa$, it is
impossible to instantiate them with a polytype, thereby limiting us to
predicative polymorphism. 

The kinding judgements $\judgeWK{\tau}{\kappa}$ and
$\judgeWK{A}{\bigstar}$ determine whether a monotype or polytype
(respectively). Notice that we use two judgements, because we do not
give polytypes their own first-class kind $\bigstar$ -- this means
that we can syntactically enforce the restriction that the context
$\Theta$, which is a collection of type variables and their kinds, 
can only range over kinds which can contain only monotypes. 

First, we give the rules for the monotypes. 

\begin{mathpar}
\inferrule*[right=KUnit]
          { }
          {\judgeWK{\unittype}{\star}}
\and
\inferrule*[right=KNat]
          { }
          {\judgeWK{\N}{\star}}
\and
\inferrule*[right=KProd]
          {\judgeWK{\tau}{\star} \\
           \judgeWK{\sigma}{\star}}
          {\judgeWK{\tau \times \sigma}{\star}}
\and
\inferrule*[right=KSum]
          {\judgeWK{\tau}{\star} \\
           \judgeWK{\sigma}{\star}}
          {\judgeWK{\tau + \sigma}{\star}}
\and
\inferrule*[right=KArrow]
          {\judgeWK{\tau}{\star} \\
           \judgeWK{\sigma}{\star}}
          {\judgeWK{\tau \to \sigma}{\star}}
\and
\inferrule*[right=KComp]
          {\judgeWK{\tau}{\star}}
          {\judgeWK{\monad{\tau}}{\star}}
\and
\inferrule*[right=KCont]
          {\judgeWK{\tau}{\star}}
          {\judgeWK{\cont{\tau}}{\star}}
\and
\inferrule*[right=KRef]
          {\judgeWK{A}{\bigstar}}
          {\judgeWK{\reftype{A}}{\star}}
\\
\inferrule*[right=KHyp]
          { \alpha:\kappa \in \Theta }
          { \judgeWK{\alpha}{\kappa} }
\and
\inferrule*[right=KApp]
          { \judgeWK{\tau}{\kappa' \to \kappa} \\
            \judgeWK{\tau'}{\kappa'} }
          { \judgeWK{\tau\;\tau'}{\kappa} }
\and
\inferrule*[right=KLam]
          { \judgeWK[\Theta, \alpha:\kappa']{\tau}{\kappa} }
          { \judgeWK{\fun{\alpha}{\kappa'}{\tau}}{\kappa' \to \kappa} }
\end{mathpar}

Next, we can give the rules for polytypes. 

\begin{mathpar}
\inferrule*[right=KUnit]
          { }
          {\judgeWK{\unittype}{\bigstar}}
\and
\inferrule*[right=KNat]
          { }
          {\judgeWK{\N}{\bigstar}}
\and
\inferrule*[right=KProd]
          {\judgeWK{\tau}{\bigstar} \\
           \judgeWK{\sigma}{\bigstar}}
          {\judgeWK{\tau \times \sigma}{\bigstar}}
\and
\inferrule*[right=KSum]
          {\judgeWK{\tau}{\bigstar} \\
           \judgeWK{\sigma}{\bigstar}}
          {\judgeWK{\tau + \sigma}{\bigstar}}
\and
\inferrule*[right=KArrow]
          {\judgeWK{\tau}{\bigstar} \\
           \judgeWK{\sigma}{\bigstar}}
          {\judgeWK{\tau \to \sigma}{\bigstar}}
\and
\inferrule*[right=KComp]
          {\judgeWK{A}{\bigstar}}
          {\judgeWK{\monad{A}}{\bigstar}}
\and
\inferrule*[right=KCont]
          {\judgeWK{A}{\bigstar}}
          {\judgeWK{\cont{A}}{\bigstar}}
\and
\inferrule*[right=KRef]
          {\judgeWK{A}{\bigstar}}
          {\judgeWK{\reftype{A}}{\bigstar}}
\\
\inferrule*[right=KHyp]
          { \alpha:\star \in \Theta }
          { \judgeWK{\alpha}{\bigstar} }
\and
\inferrule*[right=KApp]
          { \judgeWK{\tau}{\kappa' \to \star} \\
            \judgeWK{\tau'}{\kappa'} }
          { \judgeWK{\tau\;\tau'}{\bigstar} }
\\
\inferrule*[right=KForall]
           { \judgeWK[\Theta, \alpha:\kappa]{A}{\bigstar} }
           { \judgeWK{\forall \alpha:\kappa.\;A}{\bigstar} }
\and
\inferrule*[right=KExists]
           { \judgeWK[\Theta, \alpha:\kappa]{A}{\bigstar} }
           { \judgeWK{\exists \alpha:\kappa.\;A}{\bigstar} }
\end{mathpar}

Types also support a pair of equality judgements 
$\judgeKeq{\tau}{\tau'}{\kappa}$ and $\judgeKeq{A}{B}{\bigstar}$. 
These two judgements implement the $\beta$- and $\eta$-equality 
principles of the lambda calculus, along with congruence rules 
for all of the type constructors of our language. 

\begin{mathpar}
\inferrule[]
          { }
          {\judgeKeq{1}{1}{\star}}
\and
\inferrule[]
          { }
          {\judgeKeq{\N}{\N}{\star}}
\and
\inferrule[]
          {\judgeKeq{\tau}{\tau'}{\star} \\
           \judgeKeq{\sigma}{\sigma'}{\star}}
          {\judgeKeq{\tau \times \sigma}{\tau' \times \sigma'}{\star}}
\and
\inferrule[]
          {\judgeKeq{\tau}{\tau'}{\star} \\
           \judgeKeq{\sigma}{\sigma'}{\star}}
          {\judgeKeq{\tau \times \sigma}{\tau' + \sigma'}{\star}}
\and
\inferrule[]
          {\judgeKeq{\tau}{\tau'}{\star} \\
           \judgeKeq{\sigma}{\sigma'}{\star}}
          {\judgeKeq{\tau \times \sigma}{\tau' \to \sigma'}{\star}}
\and
\inferrule[]
          { \judgeKeq{\tau}{\tau'}{\star} }
          { \judgeKeq{\monad{\tau}}{\monad{\tau'}}{\star} }
\and
\inferrule[]
          { \judgeKeq{\tau}{\tau'}{\star} }
          { \judgeKeq{\cont{\tau}}{\cont{\tau'}}{\star} }
\and
\inferrule[]
          { \judgeKeq{A}{A'}{\bigstar} }
          { \judgeKeq{\reftype{A}}{\reftype{A'}}{\star} }
\and
\inferrule[]
          { \alpha:\kappa \in \Theta }
          { \judgeKeq{\alpha}{\alpha}{\kappa} }
\and
\inferrule[]
          { \judgeKeq{\tau}{\sigma}{\kappa' \to \kappa} \\
            \judgeKeq{\tau'}{\sigma'}{\kappa'}}
          { \judgeKeq{\tau \; \tau'}{\sigma \; \sigma'}{\kappa} }
\and
\inferrule[]
          { \judgeWK{(\fun{\alpha}{\kappa'}{\tau})\;\tau'}{\kappa} }
          { \judgeKeq{(\fun{\alpha}{\kappa'}{\tau})\;\tau'}
                     {[\tau'/\alpha]\tau}
                     {\kappa} }
\and
\inferrule[]
          { \judgeKeq[\Theta, \alpha:\kappa']
                     {\tau\;\alpha}{\sigma\;\alpha}{\kappa} }
          { \judgeKeq{\tau}{\sigma}{\kappa' \to \kappa} }
\end{mathpar}

\noindent Now we can give the equality judgement for polytypes.  The
only rules we have for this judgement are simple congruence rules, 
plus a recursive call back to the other equality judgement whenever
we need to compare monotyped terms. 

\begin{mathpar}
\inferrule[]
          { }
          {\judgeKeq{1}{1}{\bigstar}}
\and
\inferrule[]
          { }
          {\judgeKeq{\N}{\N}{\bigstar}}
\and
\inferrule[]
          {\judgeKeq{A}{A'}{\bigstar} \\
           \judgeKeq{B}{B'}{\bigstar}}
          {\judgeKeq{A \times B}{A' \times B'}{\bigstar}}
\and
\inferrule[]
          {\judgeKeq{A}{A'}{\bigstar} \\
           \judgeKeq{B}{B'}{\bigstar}}
          {\judgeKeq{A \times B}{A' + B'}{\bigstar}}
\and
\inferrule[]
          {\judgeKeq{A}{A'}{\bigstar} \\
           \judgeKeq{B}{B'}{\bigstar}}
          {\judgeKeq{A \times B}{A' \to B'}{\bigstar}}
\and
\inferrule[]
          { \judgeKeq{A}{A'}{\bigstar} }
          { \judgeKeq{\monad{A}}{\monad{A'}}{\bigstar} }
\and
\inferrule[]
          { \judgeKeq{A}{A'}{\bigstar} }
          { \judgeKeq{\cont{A}}{\cont{A'}}{\bigstar} }
\and
\inferrule[]
          { \judgeKeq{A}{A'}{\bigstar} }
          { \judgeKeq{\reftype{A}}{\reftype{A'}}{\bigstar} }
\and
\inferrule[]
          { \alpha:\kappa \in \Theta }
          { \judgeKeq{\alpha}{\alpha}{\kappa} }
\and
\inferrule[]
          { \judgeKeq{\tau \; \sigma}{\tau' \; \sigma'}{\star} }
          { \judgeKeq{\tau \; \sigma}{\tau' \; \sigma'}{\bigstar} }
\and
\inferrule[]
          { \judgeKeq{\Theta, \alpha:\kappa}{A}{B}{\bigstar} }
          { \judgeKeq{\forall \alpha:\kappa.\;A}
                     {\forall \alpha:\kappa.\;B}
                     {\bigstar} }
\and
\inferrule[]
          { \judgeKeq{\Theta, \alpha:\kappa}{A}{B}{\bigstar} }
          { \judgeKeq{\exists \alpha:\kappa.\;A}
                     {\exists \alpha:\kappa.\;B}
                     {\bigstar} }
\end{mathpar}

Because types and kinds form an instance of the simply typed lambda
calculus, we know that there is a unique $\beta$-normal, $\eta$-long
form for each well-kinded type expression. This means that when we
quotient the set of well-kinded terms by the equality judgement, we
know that each equivalence class contains a single long normal term.

\subsection{Semantics of Types}

Now, we want to give a semantics for these types, which we will then
use to interpret terms of our programming language. Repeating the
design criteria mentioned earlier, we need: 

\begin{itemize}
\item Our interpretation of types should make all non-monadic types 
  pure. 
\item In particular, I want to treat even nontermination as a side
  effect, in addition to the more-obvious effects of control and state. 
\end{itemize}

The purpose of this choice is twofold. First, it will give us a rich
subset of the language which is total and pure, which will be convenient
when writing assertions about programs -- we will be able to use any pure 
function directly in an assertion, without having to worry about any 
side effects it might have. Second, purity means that we will get a 
very rich equality theory for the language -- both the $\beta$ \emph{and}
$\eta$ laws will hold for all of the types of the programming language,
which will facilitate equational reasoning about the pure part of the 
programming language. 

Because we count nontermination as an effect, our denotational
semantics must be in CPO, the category of complete partial orders and
continuous functions between them. Note that we do not demand that all
domains have least elements -- that is, we only require that the
objects of this category be \emph{predomains}, rather than domains. As
a result, we can we can model pure types as predomains lacking a
bottom element.

We begin by giving an interpretation of the closed monotypes (i.e.,
monotypes of kind $\star$, with no free occurrences of type variables
within them).  

\begin{displaymath}
\interpmono{-} : \mbox{Monotype} \to CPO_\bot \times CPO^{op}_\bot \to CPO   
\end{displaymath}
\begin{displaymath}
\begin{array}{lcl}
Loc(A) & = & \N \times \setof{A} \\
Loc    & = & \bigcup \setof{X \;|\; \exists A.\; (\judgeWK[\cdot]{A}{\bigstar}) \;\land\;X = Loc(A)} \\[1em]

\interpmono{\judgeWK[\cdot]{\unittype}{\star}}(K_+, K_-) & = & \setof{*} \\

\interpmono{\judgeWK[\cdot]{\N}{\star}}(K_+, K_-) & = &  \N \\

\interpmono{\judgeWK[\cdot]{\tau \times \sigma}{\star}}(K_+, K_-) & = & 
  \interpmono{\judgeWK[\cdot]{\tau}{\star}}(K_+, K_-) \times 
  \interpmono{\judgeWK[\cdot]{\sigma}{\star}}(K_+, K_-) \\

\interpmono{\judgeWK[\cdot]{\tau + \sigma}{\star}}(K_+, K_-) & = & 
  \interpmono{\judgeWK[\cdot]{\tau}{\star}}(K_+, K_-) + 
  \interpmono{\judgeWK[\cdot]{\sigma}{\star}}(K_+, K_-) \\


\interpmono{\judgeWK[\cdot]{\tau \to \sigma}{\star}}(K_+, K_-) & = & 
  \interpmono{\judgeWK[\cdot]{\tau}{\star}}(K_-, K_+) \to
  \interpmono{\judgeWK[\cdot]{\sigma}{\star}}(K_+, K_-) \\

\interpmono{\judgeWK[\cdot]{\reftype{A}}{\star}}(K_+, K_-) & = & Loc(A) \\

\interpmono{\judgeWK[\cdot]{\cont{\tau}}{\star}}(K_+, K_-) & = & 
    \interpmono{\judgeWK[\cdot]{\tau}{\star}}(K_-,K_+) \to K_+ \\

\interpmono{\judgeWK[\cdot]{\monad{\tau}}{\star}}(K_+, K_-) & = & 
   (\interpmono{\judgeWK[\cdot]{\tau}{\star}}(K_+, K_-) \to K_-) \to K_+ \\[1em]
\end{array}
\end{displaymath}

Before explaining the clauses in detail, I will explain why this
defines a function at all. First, because we are considering closed
terms of kind $\star$, the normalization theorem tells us that any
such term will normalize to one of the cases listed above. In
particular, we will never bottom out at a variable, because the
context is closed. We will never bottom out at a lambda, because we
are considering only the kind $\star$, and we will never bottom out an
application, because there will be room for further beta-reduction in
this case, and by hypothesis we are only considering the normal forms.

This means we cover all of the possibilities in this definition, and
furthermore we know it is well-founed, because all of the recursive
calls to $\interpmono{-}$ are always on immediate subterms of the
type.

Most of the clauses of this definition should be relatively
straightforward --- the main mystery is that we have parameterized this
interpretation by two arguments $K_+$ and $K_-$, which I will explain
when we reach the continuation and monadic type constructors. 
We interpret the unit type as the one-element, discretely ordered
predomain, the natural number type as the natural numbers with a
discrete order, pairs as the categorical products of $CPO$, sums as
coproducts, and functions via the exponentials of $CPO$.

Reference types $\reftype{A}$ are interpreted as pairs consisting of
natural numbers and the syntactic object $A$. The intuition is that
references are just numbers, together with a type tag saying what
type of value the reference will point to. It's important that we do 
\emph{not} interpret the type tag $A$ in this definition --- a ref cell
is a number plus the purely syntactic object $A$, acting as a label. 
To do otherwise would make our definition circular. 

The first time we use $K$ is when we interpret the type $\cont{\tau}$.
Now, the $K_+$ and $K_-$ arguments are revealed as the positive and
negative occurences of the ``answer type'' of a continuation. That is,
we interpret $\cont{\tau}$ as the function space
$\interpmono{\tau}(K_-, K_+) \to K_+$.  Notice that the positive and
negative occurences trade places on the recursive call, because it
occurs on the left-hand-side of a function space. Likewise, the
monadic type $\monad{\tau}$ is interpreted as a sort of
double-negation: $(\interpmono{\tau}(K_+, K_-) \to K_-) \to K_+$.

However, a careful reader will have noticed that so far our
definitions do not mention state at all. What will ultimately happen
is that we will interpret continuations as functions from heaps to the
two-point Sierpinski lattice $O = \setof{\top, \bot}$. However, since
heaps can contain references to values of polymorphic type, and since
we have not yet defined how the semantics of polymorphic types work, we
have carefully parameterized our functorial semantics of monotypes so
that we do not needed to mention them explicitly. 

To fix this gap, we will give an interpretation of polymorphic types
as an indexed function from a context of closed monokinded type
constructors to a a CPO.  As before, we parameterize by the
continuation arguments.

\begin{displaymath}
\begin{array}{lcl}\interp{\judgeWK{A}{\bigstar}} &\in& \mathrm{Type Context} \to (CPO_\bot \times CPO^{op}_\bot) \to CPO 
\\[1em]
\interp{\judgeWK{\alpha}{\bigstar}}\;\eta\;(K_+,K_-) & = & 
    \interpmono{\judgeWK[\cdot]{\eta(\alpha)}{\star}}(K_+, K_-) 
\\
\interp{\judgeWK{\tau\;\tau'}{\bigstar}}\;\eta\;(K_+,K_-) & = & 
    \interpmono{\judgeWK[\cdot]{\eta(\tau)\;\eta(\tau')}{\star}}(K_+, K_-) 
\\
\interp{\judgeWK{\forall \alpha:\kappa.\;A}{\bigstar}}\;\eta\;(K_+,K_-) & = & 
    \Pi \tau:\kappa.\; 
        \interp{\judgeWK[\Theta, \alpha:\kappa]{A}{\bigstar}}\;(\eta,\tau)\;(K_+,K_-) 
\\
\interp{\judgeWK{\exists \alpha:\kappa.\;A}{\bigstar}}\;\eta\;(K_+,K_-) & = & 
    \Sigma \tau:\kappa.\; 
        \interp{\judgeWK[\Theta, \alpha:\kappa]{A}{\bigstar}}\;(\eta,\tau)\;(K_+,K_-) 
\\
\interp{\judgeWK{A \times B}{\bigstar}}\;\eta\;(K_+,K_-) & = & 
   \interp{\judgeWK{A}{\bigstar}}\;\eta\;(K_+,K_-) \times
   \interp{\judgeWK{B}{\bigstar}}\;\eta\;(K_+,K_-) 
\\
\interp{\judgeWK{A + B}{\bigstar}}\;\eta\;(K_+,K_-) & = & 
   \interp{\judgeWK{A}{\bigstar}}\;\eta\;(K_+,K_-) +
   \interp{\judgeWK{B}{\bigstar}}\;\eta\;(K_+,K_-) 
\\
\interp{\judgeWK{A \to B}{\bigstar}}\;\eta\;(K_+,K_-) & = & 
   \interp{\judgeWK{A}{\bigstar}}\;\eta\;(K_-,K_+) \to
   \interp{\judgeWK{B}{\bigstar}}\;\eta\;(K_+,K_-) 
\\
\interp{\judgeWK{\unittype}{\bigstar}}\;\eta\;(K_+, K_-) & = & \setof{*} 
\\

\interp{\judgeWK{\N}{\bigstar}}\;\eta\;(K_+, K_-) & = &  \N 
\\
\interp{\judgeWK{\cont{A}}{\bigstar}}\;\eta\;(K_+,K_-) & = & 
   \interp{\judgeWK{A}{\bigstar}}\;\eta\;(K_-,K_+) \to K_+
\\
\interp{\judgeWK{\monad{A}}{\bigstar}}\;\eta\;(K_+,K_-) & = & 
   (\interp{\judgeWK{A}{\bigstar}}\;\eta\;(K_+,K_-) \to K_-) \to K_+
\\
\interp{\judgeWK{\reftype{A}}{\star}}\;\eta\;(K_+, K_-) & = & Loc(A) 
\\
\end{array}
\end{displaymath}

This definition is also well-founded, since it is defined by a
structural recursion over the canonical forms of the kinding
derivation of $\judgeWK{A}{\bigstar}$. 

Whenever we reach a variable or application case, we can apply the
substitution and invoke the intepretation function for the
monotypes. Universal types $\forall \alpha:\kappa.\;A$ are interpreted
as set-indexed predomains or dependent functions from the set of
closed objects of the kind $\kappa$ into predodmains. Existential
types $\exists \tau:\kappa.\;A$ are interpreted as pairs or dependent
sums: we pair a syntactic monotype with the predomain interpreting the
second component.

The remaining cases essentially repeat the clauses of the definitions
for monotypes, to allow for the possibility that there may be
sub-components of pairs/sums/functions/etc that contain universal or
existential types.

Now we are finally in a position to define the recursive domain equation we 
would like to solve:

\begin{displaymath}
\begin{array}{lcl}
H(K_+,K_-) & = & \Sigma L \subseteq^{fin} Loc.\; 
                    \left(\Pi (l,A) \in L.\; 
                             \interp{\judgeWK[\cdot]{A}{\bigstar}}(\cdot)\;(K_+,K_-) 
                    \right)\\

\mathcal{K}(K_+,K_-) & = & H(K_-,K_+) \to O \\    
\end{array}
\end{displaymath}

We use $H$ to define what heaps mean. A heap is a pair whose first
component is a finite set of allocated locations, together with a map
that takes each location in the set of allocated location and returns 
a value of the appropriate type. 

The answer type $\mathcal{K}$ is itself a function type, which takes a
heap and returns an element of the Sierpinski lattice $O$. So if we
can solve the equation $K = \mathcal{K}(K, K)$, then we can plug $K$
into all our other definitions to interpret all of the types in our
language.

Filling this in, we can understand how continuations of type
$\cont{\tau}$ work: they receive a value of type $\tau$ and a heap,
and then either loop or terminate. The monadic type $\monad{\tau}$ now
can be seen as the state-and-continuation monad, which combines the
effects of the continuation monad and the state monad via a domain 
which looks a bit like $(\tau \to H \to O) \to H \to O$. 


To show that this equation actually has a solution, it suffices to 
show that $F$ is a locally-continuous functor. We'll prove this by 
induction over $\interp{-}$ and $\interpmono{-}$, and then at each
case appeal to a series of lemmas showing that each construction we
use preserves local continuity. 


\begin{lemma}{Local Continuity}
\begin{enumerate}
\item If $F,G : CPO_\bot \times CPO^{op}_\bot \to CPO$ are locally continuous,
      then $F \times G$ is locally continuous.  
\item If $F,G : CPO_\bot \times CPO^{op}_\bot \to CPO$ are locally continuous,
      then $F + G$ is locally continuous.  
\item If $F,G : CPO_\bot \times CPO^{op}_\bot \to CPO$ are locally continuous,
      then $F \to G$ is locally continuous.  
\item The constant functor $K_C$ is locally continuous. 
\item If X is a set, and $F(x) : CPO_\bot \times CPO^{op}_\bot \to CPO$ is an
      $X$-indexed family of locally continuous functors, then 
      $\Pi x:X.\;F(x)$ is a locally continuous functor. 
\item If X is a set, and $F(x) : CPO_\bot \times CPO^{op}_\bot \to CPO$ is an
      $X$-indexed family of locally continuous functors, then 
      $\Sigma x:X.\;F(x)$ is a locally continuous functor. 
\end{enumerate}
\end{lemma}
 
\textbf{Proof.}

\begin{enumerate}
\item Suppose $F$ and $G$ are locally continuous. Now, we define 
$F \times G$ to be the functor which takes $(A,B)$ to $F(A,B) \times G(A,B)$
on the object part, and which takes $(f,g)$ to $F(f,g) \times G(f,g)$ on
the arrow part.

Next, suppose that we have a chain of functions $\left<f_i\right> : A \to B$ and
$\left<g_i\right> : X \to Y$. Now, we calculate:

\begin{displaymath}
\begin{array}{lcl}
  \sqcup_i (F \times G (f_i,g_i)) 
   & = & \sqcup_i (F(f_i,g_i) \times G(f_i,g_i)) \\
   & = & \sqcup_i \left<F(f_i,g_i) \circ \pi_1; 
                        G(f_i,g_i) \circ \pi_2\right>\\
   & = & \left<\sqcup_i (F(f_i,g_i) \circ \pi_1);
               \sqcup_i (G(f_i,g_i) \circ \pi_2)\right> \;\;\;\;(*)\\
   & = & \left<\sqcup_i F(f_i,g_i) \circ \sqcup_i \pi_1;
               \sqcup_i G(f_i,g_i) \circ \sqcup_i \pi_2\right>\\
   & = & \left<\sqcup_i F(f_i,g_i) \circ \pi_1);
               \sqcup_i G(f_i,g_i) \circ \pi_2)\right>\\
   & = & (\sqcup_i F(f_i,g_i)) \times (\sqcup_i G(f_i,g_i))\\
\end{array}
\end{displaymath}

The interesting step is marked with (*); it is justified by the fact
that we know that $\pi_j \circ (\sqcup_i \left<h^1_i;h^2_i\right>) = 
\sqcup_i (\pi_j \circ \left<h^1_i;h^2_i\right>) = 
\sqcup_i h^j_i$,
and that $\pi_j \circ \left<\sqcup_i h^1_i; \sqcup_i h^2_i\right> = \sqcup_i h^j_i$,
and that the mediating morphism is unique. 


\item Suppose $F$ and $G$ are locally continuous. Now, we define 
$F + G$ to be the functor which takes $(A,B)$ to $F(A,B) + G(A,B)$
on the object part, and which takes $(f,g)$ to $F(f,g) + G(f,g)$ on
the arrow part.

Next, suppose that we have a chain of functions $\left<f_i\right> : C \to A$ and
$\left<g_i\right> : B \to D$. Now, we calculate:

\begin{displaymath}
\begin{array}{lcl}
  \sqcup_i (F + G (f_i,g_i)) 
   & = & \sqcup_i (F(f_i,g_i) + G(f_i,g_i)) \\
   & = & \sqcup_i \left[\inl \circ F(f_i,g_i); 
                        \inr \circ G(f_i,g_i)\right]\\
   & = & \left[\inl \circ \sqcup_i (F(f_i,g_i));
               \inr \circ \sqcup_i (G(f_i,g_i))\right] \;\;\;\;(*)\\
   & = & \left[\sqcup_i \inl \circ F(f_i,g_i);
               \sqcup_i \inr \circ G(f_i,g_i) \right]\\
   & = & \left[\inl \circ \sqcup_i F(f_i,g_i));
               \inr \circ \sqcup_i G(f_i,g_i))\right]\\
   & = & (\sqcup_i F(f_i,g_i)) + (\sqcup_i G(f_i,g_i))\\
\end{array}
\end{displaymath}

The interesting step is marked with (*); it is justified by the fact
that we know that $(\sqcup_i \left[h^1_i;h^2_i\right]) \circ
\mathsf{in}_j = 
\sqcup_i (\left[h^1_i;h^2_i\right] \circ \mathsf{in}_j) = 
\sqcup_i h^j_i$, and that $\left<\sqcup_i h^1_i; \sqcup_i
h^2_i\right> \circ \mathsf{in}_j = \sqcup_i h^j_i$, and that the mediating
morphism is unique.

\item Suppose $F$ and $G$ are locally continuous. Now, we define 
$F \to G$ to be the functor which takes $(A,B)$ to $F(B,A) \to G(A,B)$
on the object part, and which takes $(f,g)$ to $F(g,f) \to G(f,g)$ on
the arrow part.
 
Next, suppose that we have a chain of functions $\left<f_i\right> : A \to C$ 
and $\left<g_i\right> : D \to B$. Now, we calculate:
 
\begin{displaymath}
\begin{array}{lcl}
\sqcup_i [F \to G](f_i,g_i) & = & F(g_i,f_i) \to G(f_i,g_i) \\
& = & 
  \sqcup_i \lambda h.\; [G(f_i,g_i) \circ h \circ F(g_i, f_i)] \\
& = & 
  \lambda h.\; \sqcup_i [G(f_i,g_i) \circ h \circ F(g_i, f_i)]  \\
& = & 
  \lambda h.\; [(\sqcup_i G(f_i,g_i)) \circ h \circ (\sqcup_i F(g_i, f_i))] \\
& = & 
  \lambda h.\; [G(\sqcup_i f_i, \sqcup_ig_i) \circ h \circ 
                F(\sqcup_i g_i, \sqcup_i f_i)] \\
\end{array}
\end{displaymath}

% The interesting step is at (*). 



% F(g : D -> B, f : A -> C) : F(D,C) -> F(B,A)
% G(f : A -> C, g : D -> B) : G(A,B) -> G(C,D)
% 
% F(g,f) : F(D,C) -> F(B,A)
% G(f,g) : G(A,B) -> G(C,D)
% 
% F(g,f) -> G(f,g) : (F(B,A) -> G(A,B)) -> F(D,C) -> G(C,D)
%                  = \lambda h. G(f,g) \circ h \circ F(g,f)
% 





\item The constant functor is locally continuous because it maps all 
morphisms to the identity morphism, and hence trivially preserves 
limits. 

\item Suppose $X$ is a set, and $F(x)$ is an $X$-indexed family of
locally continuous functors. We define $\Pi x:X.\; F(x)$ as
following. 

First, given objects $(A,B)$, we define the object part of this as the
dependent function space $\Pi x:X.\; F(x)(A,B)$, with elements $u
\sqsubseteq v$ if and only if for all $x \in X$, $u(x)
\sqsubseteq_{F(x)(A,B)} v(x)$. 

It's worth noting that this object is a true product over $X$. Given
$\Pi x:X.\; F(x)(A,B)$, we can define the $x$-th projection as $\pi_x
= \lambda f.\; f(x)$. Then, it's clear that given a family of 
morphisms $f_x : Y \to F(x)(A,B)$, we can define a function 
$\left<f_x\right> : Y \to \Pi x:X.\;F(x)(A,B) = \lambda y.\; \lambda x.\; f_x(y)$, 
which means that for all $x$, and that $\pi_x \circ \left<f_x\right> = f_x$. 

We show uniqueness by supposing that that there is some $g$ such
that $\pi_x \circ g = f_x$. Then, we know that 
$g = \lambda x.\; pi_x \circ g$, which means that $g = \lambda x.\; f_x$,
which is exactly $\left<f_x\right>$. 


Next, given morphisms $f \in A \to C$ and $g \in D \to B$, we define
$[\Pi x:X.\; F(x)](f,g) \in [\Pi x:X.\; F(x)](A,B) \to [\Pi x:X.\; F(x)](C,D)$
as:
  
\begin{displaymath}
  [\Pi x:X.\; F(x)](f,g) = \lambda x.\; F(x)(f,g)
\end{displaymath}

Clearly, this preserves identities and composition, and is hence a
functor. 

Now, suppose that $(f,g) \sqsubseteq (f',g')$, and that $x$ is an
arbitrary element of $X$. Then $[\Pi x:X.\; F(x)](f,g) = F(x)(f,g)$
and $[\Pi x:X.\; F(x)](f',g') = F(x)(f',g')$. Since $F(x)$ is a
locally continuous functor, we know that $F(x)(f,g) \sqsubseteq
F(x)(f',g')$, and so $[\Pi x:X.\; F(x)]$ preserves ordering.

Now, suppose that $(f_i,g_i)$ form a chain. So, we know that 

\begin{displaymath}
\begin{array}{lcl}
\sqcup_i ([\Pi x:X.\; F(x)](f_i,g_i)) & = & 
  \sqcup_i (\lambda x:X.\; (F(x) (f_i, g_i))) \\
& = & 
  \lambda x:X.\; (\sqcup_i (F(x) (f_i, g_i))) \;\;\;\;(*) \\
& = & 
  \lambda x:X.\; (F(x) (\sqcup_i (f_i, g_i))) \\
& = & 
[\Pi x:X.\; F(x)] (\sqcup_i (f_i,g_i)) \\
\end{array}
\end{displaymath}

The interesting step is (*); it is justified by the fact
that we know that $\pi_x \circ \sqcup_i \left<h^x_i\right> =  
\sqcup_i (\pi_x \circ_i \left<h^x_i\right>) = 
\sqcup_i h^x_i$, 
and that $\pi_x \circ \left<\sqcup_i h^x_i\right> 
          = \sqcup_i h^x_i$, 
and that the mediating morphism is unique.

As a result, we can conclude that this functor is locally 
continuous.

\item Suppose $X$ is a set, and $F(x)$ is an $X$-indexed family
of locally continuous functors. We define the functor $\Sigma x:X.\;
F(x)$ as following.

First, given objects $(A,B)$, we define the object part of the functor
as yielding the dependent sum $\Sigma x:X.\; F(x)(A,B)$. Ordering is
given pairwise, equipping the set $X$ with the trivial ordering. 
That is $(x,o) \sqsubseteq (x', o')$ if and only if $x = x'$ and 
$o \sqsubseteq_{F(x)(A,B)} o'$. 

It's worth noting that this is a true coproduct over $X$. Given
$\Sigma x:X.\; F(x)(A,B)$, we can define the injections $\inj{x} \in
F(x)(A,B) \to \Sigma x:X.\; F(x)(A,B)$ as $\lambda v. (x,v)$. 
Next, suppose we have a family of functions $f_x : F(x)(A,B) \to Y$. 
We can define a function $[f_x] \in (\Sigma x:X.\; F(x)(A,B)) \to Y$ as
$\lambda (x,v).\; (f_x\;v)$. It's clear that $[f_x]\circ \inj{i} = f_i$. 

Finally, we can establish uniqueness as follows. Suppose that there 
is a $g$ such that $g \circ \inj{i} = f_i$. Next, we know that 
$g = \lambda (x,v).\;g (x, v) = \lambda (x,v).\;(g\circ\inj{x})(v)$,
which is clearly $\lambda (x,v).\; (f_x\;v)$, which is just $[f_x]$


Next, given morphisms $f \in A \to C$ and $g \in D \to B$, we define
$[\Sigma x:X.\; F(x)](f,g) \in [\Pi x:X.\; F(x)](A,B) \to [\Sigma x:X.\; F(x)](C,D)$
as:

\begin{displaymath}
  [\Sigma x:X.\; F(x)](f,g) = \lambda (x, v).\; (x, F(x)(f,g)(v))
\end{displaymath}

This clearly preserves identities and composition, and hence defines
a functor. 

Now, suppose that $(f,g) \sqsubseteq (f',g')$ and that $(x,v)$ is
an element of $\Sigma x:X.\; F(x)(A,B)$. Then we have that
$[\Sigma x:X.\;F(x)](f,g)](x,v) = (x,F(x)(f,g)(v))$ and that
$[\Sigma x:X.\;F(x)](f',g')](x,v) = (x,F(x)(f',g')(v))$. So we
know that $x=x$, and by the local continuity of $F(x)$, we know
that $F(x)(f,g)(v) \sqsubseteq F(x)(f',g')(v)$. So this functor
preserves ordering. 

Finally, suppose $(f_i, g_i)$ form a chain. 

\begin{displaymath}
\begin{array}{lcl}
\sqcup_i [\Sigma x:X.\;F(x)](f_i,g_i) 
& = & \sqcup_i \lambda (x,v).\; (F(x)(f_i,g_i)(v)) \\
& = & \lambda (x,v). \sqcup_i (F(x)(f_i,g_i)(v)) \;\;\;\; (*) \\
& = & \lambda (x,v).\; F(x)(\sqcup_i f_i, \sqcup_i g_i))(v) \\
& = & [\Sigma x:X.\;F(x)](\sqcup_i f_i, \sqcup_i g_i) \\
\end{array}
\end{displaymath}

The interesting step is (*); it is justified by the fact
that we know that 
$(\sqcup_i [h^x_i]) \circ \inj{x} =  
\sqcup_i ([h^x_i] \circ \inj{x}) =  \sqcup_i h^x_i$, 
and that $[\sqcup_i h^x_i] \circ \inj{x} = \sqcup_i h^x_i$, 
and that the mediating morphism is unique.
\end{enumerate}

Now that we know that the basic operations we use in our
interpretation are 

\begin{lemma}{Functoriality of $\interpmono{-}$ and $\interp{-}$}
  \begin{enumerate}
  \item For all canonical derivations $\judgeWK[\cdot]{\tau}{\star}$, 
    $\interpmono{\judgeWK[\cdot]{\tau}{\star}}$ is locally continuous. 
  \item For all canonical derivations $\judgeWK[\cdot]{A}{\bigstar}$, 
    $\interp{\judgeWK[\cdot]{A}{\bigstar}}$ is locally continuous. 
  \item $H$ is a locally continuous functor
  \item $\mathcal{K}$ is a locally continuous functor. 
  \end{enumerate}
\end{lemma}

\textbf{Proof.} The proof of the first case follows by structural
induction on the canonical derivations of monotypes. This is then used
as a lemma in the proof of the second case, which is done via a
structural induction on the canonical derivations of polytypes. This
then lets us prove the third case, that $H$ is a locally-continuous
functor, because we can work from the inside out, using the fact that
set-indexed sums and products of locally-continuous functors are
themselves locally continuous. Finally, since $\mathcal{K}$ is just 
$H \to K_O$, we know it is locally continuous also. 

Observe that $\mathcal{K}$, applied to any arguments, yields a pointed
domain, since the Sierpinski domain is pointed, and a function space
into a pointed domain is itself pointed. Hence our functor $K$ is also
a functor into $CPO_\bot$, the category of complete \emph{pointed}
partial orders and continuous functions. Now, we can apply Pitts's
theorem to solve the recursive domain equation $K = \mathcal{K}(K,
K)$.

\begin{prop}{Pitts's Theorem}
Any locally-continuous functor $F : CPO_\bot \times CPO^{op}_\bot \to CPO_\bot$ has 
a solution to the equation $X = F(X)$. 
\end{prop}

\todo{Work out necessary strictness conditions}

\section{The Programming Language}

We have given the semantics of types in domain theoretic terms. Now,
we'll give the syntax and typing of the programming language. Then,
we'll use the domain-theoretic semantics just given in order to first
give a denotational semantics for the programming language, and
second, to give an interesting equality theory for it. 

\begin{displaymath}
  \begin{array}{llcl}
    \mbox{Pure expressions} & 
     e & ::= & 
         \unit \bnfalt
         \pair{e}{e'} \bnfalt
         \fst{e} \bnfalt
         \snd{e} \bnfalt 
\\
     &&& \inl{e} \bnfalt
         \inr{e} \bnfalt
         \Case{e_0}{x_1}{e_1}{x_2}{e_2} \bnfalt
\\
     &&& \z \bnfalt 
         \s{e} \bnfalt 
         \iter{e}{e_0}{x}{e_1}
\\ 
     &&& x \bnfalt \fun{x}{A}{e} \bnfalt e\;e' \bnfalt
\\ 
     &&& \Fun{\alpha}{\kappa}{e} \bnfalt e\;\tau \bnfalt
\\ 
     &&& \pack{\tau}{e} \bnfalt \unpack{\alpha}{x}{e}{e'} \bnfalt
\\
     &&& \comp{c} \bnfalt \mbox{\todo{fixed points}}
\\[1em]
  \mbox{Computations} & 
    c & ::= & e \bnfalt \letv{x}{e}{c} \bnfalt
              \newref{A}{e} \bnfalt !e \bnfalt e := e'
\\[1em]
  \end{array}
\end{displaymath}

\begin{mathpar}
\inferrule[]
          { }
          {\judgeE{\Gamma}{\unit}{\unittype}}
\\
\inferrule[]
          {\judgeE{\Gamma}{e_1}{A} \\ 
           \judgeE{\Gamma}{e_2}{B}}
          {\judgeE{\Gamma}{\pair{e_1}{e_2}}{A \times B}}
\and
\inferrule[]
          {\judgeE{\Gamma}{e}{A \times B}}
          {\judgeE{\Gamma}{\fst{e}}{A}}
\and
\inferrule[]
          {\judgeE{\Gamma}{e}{A \times B}}
          {\judgeE{\Gamma}{\snd{e}}{B}}
\\
\inferrule[]
          {\judgeE{\Gamma}{e}{A}}
          {\judgeE{\Gamma}{\inl{e}}{A + B}}
\and
\inferrule[]
          {\judgeE{\Gamma}{e}{B}}
          {\judgeE{\Gamma}{\inr{e}}{A + B}}
\and
\inferrule[]
          {\judgeE{\Gamma}{e}{A+B} \\
           \judgeE{\Gamma, x:A}{e_1}{C} \\
           \judgeE{\Gamma, y:B}{e_2}{C}}
          {\judgeE{\Gamma}{\Case{e}{x}{e_1}{y}{e_2}}{C}}
\\
\inferrule[]
          { }
          {\judgeE{\Gamma}{\z}{\N}}
\and
\inferrule[]
          {\judgeE{\Gamma}{e}{\N}}
          {\judgeE{\Gamma}{\s{e}}{\N}}
\and
\inferrule[]
          {\judgeE{\Gamma}{e}{\N} \\ 
           \judgeE{\Gamma}{e_0}{A} \\
           \judgeE{\Gamma,x:A}{e_1}{A}}
          {\judgeE{\Gamma}{\iter{e}{e_0}{x}{e_1}}{A}}
\end{mathpar}
\begin{mathpar}
\inferrule[]
          { x:A \in \Gamma }
          {\judgeE{\Gamma}{x}{A}}
\and
\inferrule[]
          {\judgeE{\Gamma, x:A}{e}{B}}
          {\judgeE{\Gamma}{\fun{x}{A}{e}}{A \to B}}
\and
\inferrule[]
          {\judgeE{\Gamma}{e}{A \to B} \\
           \judgeE{\Gamma}{e'}{A} }
          {\judgeE{\Gamma}{e\;e'}{B}}
\end{mathpar}

\end{document}
