
%
% In the tech report: include a link to the Ynot sources!
%


\section{Ynot Experiments}
\label{sec:ynot-experiments}

In this section we give a brief description of our experiments with
translating the design pattern specifications and implementations from
the earlier sections into Hoare Type Theory (HTT) and verifying them in the
Ynot implementation of HTT. More details can be found in the 
technical report~\cite{svendsen08}.

Ynot is an axiomatic extension to the Coq proof assistant, that supports
writing, reasoning about, and extracting higher-order, dependently-typed
programs with side-effects~\cite{nanevski08}.  Coq already includes a
powerful functional language that supports dependent types, but that
language is limited to pure, total functions.  Ynot extends Coq with
support for computations that may have effects such as non-termination,
accessing a mutable store, and throwing/catching exceptions.  The axioms of
Ynot form a small trusted computing base which has been formally justified
in previous work on Hoare Type Theory (HTT)~\cite{nanevski06separation,
  nanevski07esop, petersen08}.

As in the specification logic described in the earlier sections, Ynot also
makes use a monads, to ensure a monadic separation of effects and pure Coq.
In Ynot specifications are types and one of the types is the monadic type
of computations $\{ P \} x:\tau \{ Q \}$; if a computation has this type
and it is run in a heap $i$ satisfying $P$ and it terminates, then it will
produce a value $x$ of type $\tau$ and result in a new heap $j$ such that
the predicate $Q(i,j)$ holds. Loosely speaking, we may thus think of Ynot
as a type theory corresponding to the specification logic presented earlier
(XXX SHOULD USE A NAME - IDEALIZED ML ?)  under a Curry-Howard style
correspondence.  Following this intuition, we have experimented with
translating the earlier described design pattern specifications and
implementations into Ynot and formally verified them in Ynot.
We now describe the translations and the lessons learned.

Note first, however, that in Ynot post-conditions are expressed in terms of
both the initial and the final heap. This is an alternative to the use of
logical variables as expressed by universally quantifying over variables
whose scope extends to both the pre- and post-condition.  We can thus
translate an Idealized ML specification,
{\small\begin{align*}
\forall x : \tau.\ \{ P(x) \}\ comp\ \{ a : 1.\ Q(x) \}
\end{align*}}
into the following Ynot type
{\small\begin{align*}
&\{ \lambda i : \HEAP.\ \exists x : \tau.\ P\ x\ i \}\\
&\quad a : 1\\
&\{ \lambda i : \HEAP.\ \lambda j : \HEAP.\ \forall x : \tau.\ P\ x\ i
\rightarrow Q\ x\ j \}
\end{align*}}
where $i$ is the initial heap and $j$ is the terminal heap. We will usually
abbreviate this type as follows: 
{\small\begin{align*}
\{ i.\ \exists x.\ P\ x\ i \}\ a : 1\ \{ i\ j.\ \forall x.\ P\ x\ i \rightarrow Q\ x\ j \}
\end{align*}}

\subsection{Flyweight in Ynot}
\label{sec:ynot-flyweight}

Besides Hoare triples, Idealized ML's specification language contains
specifications of the form $\{ P \}$, for asserting that $P$ is true. In the
above specification this is used to express that calling $getdata$ with the
same character multiple times, produces the same reference. In HTT we can
express that a proposition $P$ is true by returning an element of
the subset type, $\{ x : 1 \mid P \}$, where $x$ is not free in $P$. 

The assertion language of Idealized ML also contains an expression for
asserting that a given specification holds. In the Flyweight specification
this is used in the post-condition of $make\_flyweight$, to assert that the
code returned implements a Flyweight. In HTT, we can express the same by
simply giving a more precise type for the return value of the
$make\_flyweight$ computation.

In the Ynot implementation, we 
have generalized the specification, such that the computation can
generate a Flyweight for simulated objects consisting of a value of an
arbitrary monotype. The Flyweight factory computation therefore also has to
take as an argument, a function, $\alpha_{eq}$, for deciding 
equality between $\alpha$ values. 

The rest of the specification can be translated almost directly into HTT,
however, we have made a few changes, to simplify the formal verification of the
implementation in Ynot. 
\begin{itemize}
\item In the specification of $newchar$, instead of using a set to associate
arguments with objects, we have used a finite function (i.e., a total function
from $\alpha$ to $\opttype\ \LOC$).
\item In the above specification the predicate $I$ has to specify the
representation of both the object table and the simulated objects. We have
split $I$ into two predicates, $table$ and $refs$, and changed the precondition
of $newchar$ to the HTT equivalent of $table(...) * (refs(...) \land
chars(S))$, to make it explicit that the object table and the simulated objects
are in separate subheaps, to simplify verification.
\end{itemize}
The final HTT type of the Flyweight factory thus looks as follows:
{\small\begin{align*}
&\Pi \alpha : \MONO.\ \Pi \alpha_{eq} : (\Pi x : \alpha.\ \Pi y : \alpha.\ \{ z : 1 \mid x = y \} + \{ z : 1 \mid x \neq y \}).\\
&\{ i.\ emp\ i \}\\
&\quad r : \Sigma table : (\alpha \rightarrow \opttype\ \LOC) \rightarrow \HEAP \rightarrow \PROP.\\
&\quad\quad \Sigma refs : (\alpha \rightarrow \opttype\ \LOC) \rightarrow \HEAP \rightarrow \PROP.\\
&\quad\quad \Sigma objat : \LOC \rightarrow \alpha \rightarrow \HEAP \rightarrow \PROP.\\
&\quad\quad\Sigma prf_1 : \{ x : 1 \mid \forall h, l, l', a, a', f.\ objat\ l\ a\ h \land objat\ l'\ a'\ h\ \land\\
&\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad refs\ f\ h \rightarrow (l = l' \leftrightarrow a = a') \}.\\
&\quad\quad \Pi a : \alpha.\\
&\quad\quad\quad \{ i.\ \exists f.\ (table\ f * (\lambda h.\ allobjat(\alpha, objat, f, h) \land refs\ f\ h))\ i \}\\
&\quad\quad\quad\quad l : \LOC\\
&\quad\quad\quad \{ i\ j.\ \forall f.\ (table\ f * (\lambda h.\ allobjat(\alpha, objat, f, h) \land refs\ f\ h))\ i \rightarrow\\
&\quad\quad\quad\quad\quad ((\forall l'.\ f\ a = Some\ l' \rightarrow l = l')\ \land\\
&\quad\quad\quad\quad\quad (table\ f[a \mapsto l] * (\lambda h.\ allobjat(\alpha, objat, f[a \mapsto l], h)\ \land\\
&\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad refs\ f[a \mapsto l]\ h))\ j) \}\ \times\\
&\quad\quad \Pi l : loc.\\
&\quad\quad\quad \{ i.\ \exists a : \alpha,\ objat\ l\ a\ i \}\\
&\quad\quad\quad\quad r : \alpha\\
&\quad\quad\quad \{ i\ j.\ \forall a : \alpha,\ objat\ l\ a\ i \rightarrow (i = j \land r = a) \}\\\
&\{ i\ j.\ ((fst\ r)\ []\ * (\lambda h.\ allobjat(\alpha, fst\ (snd\ (snd\ r)), [], h)\ \land\\
&\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad (fst\ (snd\ r))\ []\ h))\ j \}
\end{align*}}
where
\begin{align*}
allobjat(\alpha, objat, f, h) &\equiv \forall l : \LOC, o : \alpha.\ f\ o = Some\ l\ \rightarrow\\&\quad\quad\quad (objat\ l\ o * (\lambda h.\ \TRUE))\ h
\end{align*}
and $[] \equiv (\lambda x.\ None)$.

We were able to formally verify that the earlier given implementation of
the Flyweight pattern has the above type in Ynot.\footnote{The Coq script was
  XXX lines long.}

\subsection{Iterators in Ynot}
\label{sec:iterators-in-ynot}

The translation of the Iterator specification and implemenation and the
formal verification in Ynot was straightforward, except for the
verification of {\tt next}, when the iterator is a {\tt Map2}.\footnote{The
  Coq script was XXX lines long.}  In that case, the implementation makes
two recursive calls to {\tt next} that each work on two subheaps of the
initial heap and the current Ynot implementation based on the $nextvc$
tactic (see~\cite{nanevski08}) for simplifying proof obligations forces one
to prove some preciseness properties because of the use of binary
post-conditions. It is unclear whether the preciseness problem encountered
is a limitation of binary post-conditions in general or the current Ynot
implementation; we think it is the latter. We did not finish the proof for
{\tt next} in this case, either with or without $nextvc$ (without $nextvc$
the proof became too long for us to finish by hand).  New versions of Ynot
should provide better tactic support for such examples. 
We did succeed in completing the formal verification of the
iterator pattern  without the {\tt Map2} iterator.

\subsection{Subject-Observers in Ynot}
\label{sec:subject-observer-in-ynot}

The Idealized ML implementation of the subject-observer pattern uses an
assertion $S\valid$ in the predicate $good$ to express that callback functions
are "good". HTT does not support this form of assertion. However, since
specifications are types, we can express the type of pairs of $(O, f)$ such
that $f$ is a good call function with respect to the predicate $O$ with the
following type: 
{\small\begin{align*}
T &\equiv \Sigma O : \N \rightarrow \HPROP.\\
&\quad\quad (\Pi m : \N.\ \{ i.\ \exists k : \N.\ O\ k\ i\}\ a : 1\ \{ i\ j.\ \forall k : \N.\ O\ k\ i \rightarrow O\ m\ j \})
\end{align*}}
Hence, we can restrict the quantification of $os$ in the specification of
$broadcast$ and $register$ to lists of good callback functions, $\listtype T$.
We can thus express the subject-observer pattern with the following HTT type:
{\small
\begin{align*}
&\Sigma \alpha : \TYPE.\ \Sigma sub : \alpha \times \N \times \listtype T
\rightarrow \HPROP.\\
&\quad \Pi n : \N.\ \{ i.\ emp\ i \} a : \alpha \{ i\ j.\ sub\ (a, n, [])\ j \}\ \times\\
&\quad \Pi a : \alpha.\ \Pi t : T.\\
&\quad\quad\{ i.\ \exists n : \N, os : list\ T. sub\ (a, n, os)\ i \}\\
&\quad\quad\quad r : 1\\
&\quad\quad \{ i\ j.\ \forall n : \N, os : list\ T.\ sub\ (a, n, os)\ i \rightarrow sub\ (a, n, t::os)\ j
\}\ \times\\
&\quad \Pi a : \alpha.\ \Pi m : \N.\\
&\quad\quad\{ i.\ \exists n : \N, os : list\ T.\ (sub\ (a, n, os) * obs\ os)\ i \}\\
&\quad\quad\quad r : 1\\
&\quad\quad \{ i\ j.\ \forall n : \N, os : list\ T.\ (sub\ (a, n, os) * obs\ os)\ i\\
&\quad\quad\quad\quad\quad \rightarrow (sub\ (a, m, os) * obs\_at\ (os, k))\ j \}
\end{align*}}
In the Idealized ML implementation of the subject-observer, the registered
callback functions are stored in the heap. Since types and specifications are
separate in Idealized ML, the type of these computations can be very weak,
i.e., $\N \rightarrow \monad 1$, because the specification language allows us
to express that if these are "good" callback functions then the broadcast
computation will do a broadcast when performed. In HTT there is no separate
specification language, so these callback functions have to be stored with a
much stronger type, so that it is possible to infer from their type that they
are "good" callback functions when they are retrieved from the heap.  

Ynot is based on the predicative version of HTT\cite{nanevski06separation} in
which dependent sums are predicative, i.e., for $\Sigma x : A. B$ to be a
monotype, both $A$ and $B$ have to be monotypes. Since the type of heaps in Ynot is defined as a subset of the type $\N \times \Sigma \alpha : \MONO.
\alpha$ and $\MONO$ is not a monotype, it follows that the $T$ type above is not a monotype either and that values of type $T$ cannot be stored in
the heap. It is thus unclear whether it is possible to give an implementation
of the above type in Ynot.

The impredicative version of HTT \cite{petersen08} has an impredicative sum
type, $\Sigma^T x : A. B$, which is a monotype if $B$ is. Hence, in the
impredicative version of HTT, we can store values of type $T$, by using
impredicative sums. We conjecture that the implementation has the above 
type in impredicative HTT.

%%\footnote{In the technical report we further show that the HTT translation of
%%the alternative Idealized ML specification of the subject-observer pattern in
%%\cite{svendsen08} does not capture subject-observer pattern.}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: patterns
%%% End: 
