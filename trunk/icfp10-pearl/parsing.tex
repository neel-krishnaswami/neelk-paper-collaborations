\documentclass{article}
\usepackage{amsmath,amssymb}
\usepackage{mathpartir}

\newcommand{\fix}[2]{\mu {#1}.\;{#2}}
\newcommand{\lft}[1]{\left<{#1}\right.}
\newcommand{\rgt}[1]{\left.{#1}\right>}
\newcommand{\bnfalt}{\;\;|\;\;}
\newcommand{\Word}{\Sigma^{*}}
\newcommand{\ints}{\mathbb{Z}}
\newcommand{\nats}{\mathbb{N}}
\newcommand{\judgebalance}[3][\Gamma]{{#1} \vdash {#2} : {#3}}
\newcommand{\judgecat}[3]{{#1} \circ {#2} \equiv {#3}}
\newcommand{\judgesubst}[3]{{#1} \vdash {#2} : {#3}}

\newcommand{\true}{\mathsf{true}}
\newcommand{\false}{\mathsf{false}}

\newcommand{\powerset}[1]{\mathcal{P}({#1})}
\newcommand{\powersetfin}[1]{\mathcal{P}^{\mathrm{fin}}({#1})}
\newcommand{\interp}[1]{[\![{#1}]\!]}
\newcommand{\setof}[1]{\{{#1}\}}
\newcommand{\comprehend}[2]{\setof{{#1}\;|\;{#2}}}
\newcommand{\semderiv}[2]{D_{#1}({#2})}
\newcommand{\deriv}[2]{d_{#1}({#2})}
\newcommand{\call}[2]{C_{#1}({#2})}
\newcommand{\fun}[2]{\lambda {#1}.\;{#2}}
\newcommand{\IfThenElse}[3]{\mbox{if }{#1}\mbox{ then }{#2}\mbox{ else }{#3}}
\newcommand{\Let}[2]{\mbox{let }{#1} = {#2}}
\newcommand{\nullable}[1]{\mathit{null}(#1)}
\newcommand{\emptify}[1]{\delta({#1})}

\newcommand{\guard}[2]{{#1}\rhd{#2}}

\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}



\newenvironment{proof}{\noindent\textbf{Proof.}}
{\noindent\textbf{End Proof.}}
\newenvironment{caseblock}{\begin{itemize}}{\end{itemize}}
\newenvironment{case}[1]{\item \textbf{Case} {#1}\\}{}


\author{Neel Krishnaswami}
\title{Partial Parsing with Nested Words}

\begin{document}
\maketitle

\section{Bracketed Grammars}

\subsection{Notational Conventions}

Intuitively, a bracketed grammar is a grammar in which all recursive calls to
grammatical productions are wrapped in explicit open-close symbols.

So we will fix three disjoint sets $\Sigma_i, \Sigma_l,$ and $\Sigma_r$ to use
as an alphabet in what follows. The set $\Sigma_i$ is the set of basic
characters, whose elements we will denote with $a, b, c$.  The set $\Sigma_l$
is the set of the left brackets, whose elements we will denote with $\lft{a},
\lft{b}, \lft{c}$. The set $\Sigma_r$ is the set of right brackets, whose
elements we will write $\rgt{a}, \rgt{b}, \rgt{c}$. We will write $\Sigma =
\Sigma_i \cup \Sigma_l \cup \Sigma_r$, and denote its elements with $\sigma$
and $\tau$.

Formally, we define \emph{grammar expressions} via the following
BNF:

\begin{displaymath}
\begin{array}{lcll}
g & ::= & \epsilon   & \mbox{Empty String} \\
  &  |  & a          & \mbox{Single character from $\Sigma_i$} \\
  &  |  & \lft{a}    & \mbox{Single character from $\Sigma_l$} \\
  &  |  & \rgt{a}    & \mbox{Single character from $\Sigma_r$} \\
  &  |  & g \cdot g' & \mbox{Concatenation} \\ 
  &  |  & g*         & \mbox{Kleene Closure} \\
  &  |  & \bot       & \mbox{Empty Language} \\
  &  |  & g \vee g'  & \mbox{Language Union} \\
  &  |  & \fix{x}{g} & \mbox{Fixed Point} \\
  &  |  & x          & \mbox{Recursive Call} \\
\end{array}
\end{displaymath}

Note that this is essentially the language of regular expressions, extended
with an operator to take the fixed point of a language. This is (thanks
to a variant of Bekic's lemma) essentially lets us define unrestricted
context-free grammars. 

To define the bracketed languages, we will impose \emph{typing
  restrictions} on this language to ensure that open and close
parentheses match up, and that every recursive call is wrapped with an
explicit open and close symbol. 

\begin{mathpar}
  \begin{array}{llcl}
    \mbox{Contexts} & \Gamma & ::= & \cdot \bnfalt \Gamma, x \\
    \mbox{Types}    & d      & \in  & \ints \\
  \end{array}
\\
\boxed{\judgebalance{g}{d}}
\\
\inferrule*[right=TEpsilon]
           { }
           {\judgebalance{\epsilon}{0}}
\and
\inferrule*[right=TChar]
          { }
          {\judgebalance{c}{0}}
\and
\mbox{(No rule for $\lft{a}$)}
\and
\inferrule*[right=TClose]
          { }
          {\judgebalance{\rgt{b}}{+1}}
\and
\inferrule*[right=TCat]
          {\judgebalance{g_1}{d_1} \\ 
           \judgebalance{g_2}{d_2} }
          {\judgebalance{g_1\cdot g_2}{d_1 + d_2}}
\and
\inferrule*[right=TStar]
          {\judgebalance{g}{0}}
          {\judgebalance{g*}{0}}
\and
\inferrule*[right=TBot]
          { }
          {\judgebalance{\bot}{d}}
\and
\inferrule*[right=TAlt]
          {\judgebalance{g_1}{d} \\ 
           \judgebalance{g_2}{d} }
          {\judgebalance{g_1 \vee g_2}{d}}
\and
\inferrule*[right=TVar]
          {x \in \Gamma}
          {\judgebalance{\lft{a} x \rgt{b}}{0}}
\and
\inferrule*[right=TFix]
          {\judgebalance[\Gamma, x]{g}{0}}
          {\judgebalance{\fix{x}{g}}{0}}
\end{mathpar}

Here, we ascribe integers as types to our grammars, with the idea that
the type of a grammar describes the number of unbalanced parentheses
in every sentence of the grammar's language. So the grammar $\rgt{a}
\vee \rgt{b}\cdot(\lft{c}\cdot x\cdot \rgt{d})*$ has type $+1$, since
every sentence of this language has one more right-bracket than
left-bracket. This also means a language like $\epsilon \vee \rgt{a}$
will fail to typecheck, since its two sentences each have different
numbers of unbalanced parens in them.

The rule \textsc{TVar} is the only rule that lets us introduce 
variables, and it ensures that every call is guarded with a left-
and right-bracket.  

Note that the right brackets can appear in a well-typed grammar
\emph{only} in conjunction with a variable occurrence. Intuitively,
the reason for this restriction is that we will be considering
grammars that arise as derivatives of balanced grammars, and as 
we match a string from left to right, we will always meet left-brackets
before right-brackets, and so the derivative grammars will always 
only need free right-brackets. 

We will formally prove the soundness of these informal claims in the
next section.

\subsection{Semantics of Bracketed Grammars}

First, let's take the set of strings to be the free monoid $\Word$
over the set of characters, writing $\epsilon$ and $s\cdot s'$ for the
unit and join of the monoid. Now, since our language has recursive
calls, we'll need to interpret grammars as fixed points of monotone
operators.

\begin{mathpar}
\boxed{\interp{-} :  (\Gamma \to \powerset{\Word}) \to G \to \powerset{\Word}}

\\

\begin{array}{lcl}
\interp{\epsilon}\gamma    & = & \setof{\epsilon} \\
\interp{a}\gamma           & = & \setof{a} \\
\interp{\lft{b}}           & = & \setof{\lft{b}} \\
\interp{\rgt{c}}           & = & \setof{\rgt{c}} \\
\interp{g \cdot g'}\gamma  & = & \comprehend{\sigma\cdot\tau}
                                            {\sigma \in \interp{g}\gamma \mbox{ and } \tau \in \interp{g'}\gamma} \\
\interp{g*}\gamma          & = & \bigcup\limits_{n \in \nats} 
                                   \comprehend{s_1 \cdot \ldots \cdot s_n}
                                              {\forall i \in \setof{1 \ldots n}.\; s_i \in \interp{g}\gamma} \\
\interp{\bot}\gamma        & = & \emptyset \\
\interp{g \vee g'}\gamma   & = & \interp{g}\gamma \cup \interp{g'}\gamma \\
\interp{x}\gamma           & = & \gamma(x) \\
\interp{\fix{x}g}\gamma    & = & \mathit{fix}(\fun{L}{L \cup \interp{g}(\gamma, L)}) \\ 
\end{array}
\end{mathpar}

All of the cases of this definition are straightforward, with the
exception of the final case, the definition of the fixed point. In
this clause, we make use of the fact that the powerset of words forms
a complete lattice, and so by the Knaster-Tarski theorem, monotonic
functions on this lattice have least fixed points.

Since the set of languages is a Kleene algebra, we can write $g \simeq
g'$ to indicate that the two grammars have the same interpretation,
and then $(\cdot, \epsilon)$ has monoidal structure, and $(\bot,
\vee)$ has join-semilattice structure. Furthermore, from the definition
of fixed points we know that $\fix{x}{g} \simeq g[\fix{x}{g}/x]$. 

\subsubsection{Properties of Languages}

Next, we'll say a word $\sigma$ is strictly well-nested if there is a
relation $R$ on the positions in the word, such that

\begin{enumerate}
\item $R$ describes a matching between open and close brackets: 
      $i \in \mathrm{dom}(R)$ iff $\sigma(i) \in \Sigma_l$. And also,
      $j \in \mathrm{cod}(R)$ iff $\sigma(j) \in \Sigma_r$.
\item $R$ is nested: if $R(i, j)$ and $R(i', j')$ holds, then if $i \leq i'$ and $i' \leq j$, then $j' \leq j$. 
\item Brackets match up uniquely: if $R(i, j)$ and $R(i', j')$ holds, then $i = i'$ iff $j = j'$. 
\end{enumerate}

This condition is natural, but will prove a little too stringent to be
univerally applicable. Instead, we will relax it just a little, and
say a word $\sigma$ is well-nested with depth $d \in \nats$ if it can
be broken up into $|d| + 1$ strictly well-nested substrings separated
by characters from $\Sigma_r$.

Finally, we will say a language $L$ is well-nested to depth $d$, if
every string $\sigma$ in $L$ is well-nested to depth $d$.

\begin{prop}{(Semantic Nesting Lemma)}
If $\sigma_1$ is nested to depth $d_1$ and $\sigma_2$ is nested to depth $d_2$, then 
$\sigma_1\cdot\sigma_2$ is nested to depth $d_1 + d_2$.
\end{prop}

\begin{proof}
  This follows from an induction on $d_1$. Written more suggestively with ellipses, 
the proof is as follows: 

  We know $\sigma_1 = \sigma^1_1\rgt{a_1}\ldots\rgt{a_{d_1}}\sigma^{d_1+1}_1$

  We know $\sigma_2 = \sigma^1_2\rgt{b_1}\ldots\rgt{b_{d_2}}\sigma^{d_2+1}_2$.
  
  So $\sigma_1\cdot\sigma_2 = \sigma^1_1\rgt{a_1}\ldots\rgt{a_{d_1}}\sigma^{d_1+1}_1\cdot\sigma^1_2\rgt{b_1}\ldots\rgt{b_{d_2}}\sigma^{d_2+1}_2$.

  This is obviously well-nested with depth $d_1 + d_2$. 

\end{proof}

\begin{prop}
If $\judgebalance{g}{d}$, and $\gamma$ is a map from the variables in $\Gamma$ to 
languages well-nested with depth $0$, then $\interp{g}\;\gamma$ is a language well-nested 
with depth $d$. 
\end{prop}

\begin{proof}
The proof is by induction on the typing derivation of $g$. Assume we have a context $\gamma$ of well-nested
languages.

\begin{caseblock}
  \begin{case}{$\judgebalance{\epsilon}{0}$}
    We see $\interp{\epsilon}{\gamma} = \setof{\epsilon}$, which is a one-element set consisting 
    of a single well-nested word (since it has no characters in it at all). 
  \end{case}

  \begin{case}{$\judgebalance{c}{0}$}
    We see $\interp{c}{\gamma} = \setof{c}$, which is a one-element set consisting 
    of a single well-nested word (since it has no brackets in it at all). 
  \end{case}

  \begin{case}{$\judgebalance{\rgt{a}}{+1}$}
    We see $\interp{\rgt{a}}{\gamma} = \setof{\rgt{a}}$, which is a one-element set consisting 
    of a single bracket. This is a well-nested word of depth $+1$, since we can write it as a 
    word of the from $\epsilon\rgt{a}\cdot\epsilon$, and $\epsilon$ is well-nested. 
   \end{case}

  \begin{case}{$\judgebalance{g_1\cdot g_2}{d_1 + d_2}$}
    We reason as follows: 
    \begin{enumerate}
      \item By inversion, we know that $\judgebalance{g_1}{d_1}$, and $\judgebalance{g_2}{d_2}$.
      \item By the semantics, every word $\sigma$ of $\interp{g_1\cdot g_2}\gamma$ is equal to 
        $\sigma_1\cdot\sigma_2$, where $\sigma_1 \in \interp{g_1}\gamma$ and $\sigma_2 \in \interp{g_2}\gamma$. 
      \item By induction, we know that $\sigma_1$ is nested to depth $d_1$ and $\sigma_2$ is nested to depth $d_2$.
      \item By the semantic nesting lemma, we know that $\sigma_1 \cdot \sigma_2$ has nesting depth $d_1 + d_2$. 
    \end{enumerate}
  \end{case}

  \begin{case}{$\judgebalance{g*}{0}$}
    We reason as follows: 
    \begin{enumerate}
      \item By inversion, we know that $\judgebalance{g}{0}$, so every string in $\interp{g}\gamma$ is 
        well-nested. 
      \item By the semantics of languages, every word $\sigma$ in $\interp{g*}\gamma$ is a concatenation of 
        $n$ well-nested words for some $n$. 
      \item By induction on $n$ and the semantic nesting lemma, we know that $\sigma$ is well-nested. 
    \end{enumerate}
  \end{case}

  \begin{case}{$\judgebalance{\lft{a}x\rgt{b}}{0}$}
    We reason as follows: 
    \begin{enumerate}
      \item By hypothesis, we know that $\gamma(x)$ is a well-nested language of depth 0. 
      \item From the semantics we know that every word $\sigma$ of $\interp{\lft{a}x\rgt{b}}\gamma$ is 
        of the form $\lft{a}\cdot\sigma'\cdot\rgt{b}$, where $\sigma' \in \gamma(x)$. 
      \item We can construct a nesting relation for this word by adding the first and last positions 
        to the nesting relation for $\sigma'$. 
      \item This means that there are no brackets left over, so we have a nesting depth of 0. 
    \end{enumerate}
  \end{case}

  \begin{case}{$\judgebalance{\fix{x}{g}}{0}$}
    We reason as follows: 
    \begin{enumerate}
      \item By inversion, we know that $\judgebalance[\Gamma, x]{g}{0}$ holds. 
      \item By induction, given a zero-balanced language $L$ as an argument, $f = \fun{L}{\interp{g}(\gamma,L)}$
        returns a zero-balanced language. 
      \item Since the empty language is zero-balanced, $f\;\emptyset$ is
        also zero-balanced. 
      \item So, we know from the semantics that $f$ preserves zero-balance and that the least language is zero-balanced. 
      \item So we know that $h = \fun{L}{L \cup f(L)}$ is zero-balanced, since zero-balance is closed under unions. 
      \item Hence $\mathit{fix}(h)$ is also zero-balanced. 
      \item This is the denotation of $\fix{x}{g}$ at $\gamma$, so the theorem holds. 
    \end{enumerate}
  \end{case}

  \begin{case}{$\judgebalance{\bot}{d}$}
    The interpretation of $\bot$ is the empty set, which vacuously satisfies the property that
    all its elements are well-nested to depth $d$. 
  \end{case}

  \begin{case}{$\judgebalance{g_1 \vee g_2}{d}$}
    We reason as follows:
    \begin{enumerate}
      \item From the semantics $\interp{g_1 \vee g_2}\gamma = \interp{g_1}\gamma \cup \interp{g_2}\gamma$.
      \item By induction, both $\interp{g_1}\gamma$ and $\interp{g_2}\gamma$ are well-nested to depth $d$.
      \item Therefore every element in the union is well-nested to depth $d$. 
    \end{enumerate}
    
  \end{case}
\end{caseblock}

\end{proof}


% \subsection{Generalizing to Nested Word Languages}
% 
% Now that we have a definition and semantics for bracketed languages, we'll
% generalize this just a little bit, to \emph{nested word languages}. A nested
% word language is essentially a regular expression over the whole alphabet
% $\Sigma$, but which can make calls to a bracketed language. We'll define the
% set $N$ of nested word grammars with the following BNF:
% 
% \begin{mathpar}
%   \begin{array}{lcl}
%     n & ::= & \epsilon \bnfalt \sigma \bnfalt n_1 \cdot n_2 \bnfalt n* \bnfalt \bot 
%               \bnfalt n_1 \vee n_2 \bnfalt \lft{a} i \rgt{b} \\
%   \end{array}
% \end{mathpar}
% 
% The reason we make this generalization is for two reasons. First, we'd like to
% be able to specify a language that includes \emph{unbalanced} brackets, so
% that we can handle incremental addition of parentheses in an editor.  Second,
% and more importantly, nested word languages have better closure properties
% than bracketed languages do -- in particular, when we take a derivative of a
% balanced paren, the remaining string is now unbalanced.

\subsection{Relating Syntactic and Semantic Properties of Grammars}

We define the emptification operator on well-typed grammars as follows: 

\begin{mathpar}
  \begin{array}{lcl}
    \emptify{\epsilon}      & = & \true \\
    \emptify{\sigma}        & = & \false \\
    \emptify{g_1 \cdot g_2} & = & \emptify{g_1} \land \emptify{g_2}} \\
    \emptify{g*}           & = & \true \\
    \emptify{\bot}         & = & \false \\
    \emptify{g_1 \vee g_2} & = & \emptify{g_1} \vee \emptify{g_2} \\
    \emptify{\fix{x}{g}}   & = & \emptify{x} \\
    \emptify{\lft{a} x \rgt{b}} & = & \false \\
  \end{array}
\end{mathpar}

The idea is that this is an operation that returns the language
$\epsilon$ if its argument contains the empty string, and the language
$\bot$ if its argument language does not contain the empty string. Since we
restrict to well-typed grammars, all occurences of variables are 
guarded, and so the result of the emptification operator is the same under
all substitutions for the variables.  

\begin{prop}{(Emptiness Operator)}
Suppose $g$ is a well-typed grammar with free variables $\Gamma$. Then
for any assignment of languages $\gamma$ for $\Gamma$, we have that
$\emptify{g}$ is $\true$ if $\epsilon \in \interp{g}\gamma$, and is
$\false$ otherwise. 
\end{prop}

\begin{proof}
This proof is by induction on $g$. 
\begin{caseblock}
  \begin{case}{$\epsilon$}
    The interpretation of this language contains the empty string, and $\emptify{\epsilon} = \true$. 
  \end{case}

  \begin{case}{$\sigma$}
    The interpretation of this language is the one-element set containing the one-character string $c$, 
    which does not contain $\epsilon$, and we have that $\emptify{\sigma} = \false$. 
  \end{case}

  \begin{case}{$g_1\cdot g_2$}
    The interpretation $\interp{g_1\cdot g_2}\gamma$ contains the concatenations of the strings of
    $\interp{g_1}\gamma$ and $\interp{g_2}\gamma$. This can only contain an empty string if both 
    languages contain empty strings. 

    By induction, we know that in that case, both $\emptify{g_1}$ and $\emptify{g_2}$ will equal $\true$, 
    and so by the definition, we know that $\emptify{g_1\cdot g_2} = \false$. Otherwise, it will equal
    $\false$, and likewise the interpretation will not contain the empty string.
  \end{case}

  \begin{case}{$g*$}
    We know that $\interp{g*}\gamma$ contains the empty string by definition, and likewise the 
    $\emptify{g*} = \true$. 
  \end{case}

  \begin{case}{$\fix{x}{g}$}
    By induction, we know for any language $L$, that $\epsilon \in \interp{g}(\gamma, L)$  if and 
    only if $\emptify{g} = \true$. Therefore, we know that 
    $\epsilon \in \interp{g}(\gamma, \interp{\fix{x}{g}}\gamma)$ if and only if $\emptify{g} = \true$. 
    Therefore, we know that $\emptify{g} = \true$ if and only if $\epsilon \in \interp{\fix{x}{g}}\gamma$. 
  \end{case}

  \begin{case}{$\lft{a}x\rgt{b}$}
    For any language $L$, all the words in $\interp{\lft{a}x\rgt{b}}L$ are non-empty. 
    Since $\emptify{\lft{a}x\rgt{b}} = \false$, the algorithm is correct in this case. 
  \end{case}

  \begin{case}{$\bot$}
    The interpretation of this grammar is the empty set of strings, which does not
    contain the empty string. Since $\emptify{\bot} = \false$, the algorithm is correct in
    this case. 
  \end{case}

  \begin{case}{$g_1 \vee g_2$}
    We reason as follows:
    \begin{enumerate}
      \item By induction, we know that $\emptify{g_1} = \true$ when $\epsilon \in \interp{g_1}\gamma$, 
        and is $\false$  otherwise. 
      \item By induction, we know that $\emptify{g_2} = \true$ when $\epsilon \in \interp{g_2}\gamma$, 
        and is $\false$  otherwise. 
      \item The interpretation $\interp{g_1 \vee g_2}\gamma = \interp{g_1}\gamma \cup \interp{g_2}\gamma$,  
        and so $\epsilon$ is in this set if and only if it is in either $\interp{g_1}\gamma$ or in 
        $\interp{g_2}\gamma$.
      \item If it is in either one, then $\emptify{g_1 \vee g_2} = \true$ by the definition, and is 
        $\false$ otherwise. 
    \end{enumerate}
  \end{case}
\end{caseblock}
\end{proof}

\begin{lemma}{Emptiness and Balance}
If $\judgebalance{g}{d}$ is well-typed, and $\emptify{g}$, then $d = 0$. 
\end{lemma}

\begin{proof}
  This is by induction over the derivation of $g$. 
  \begin{caseblock}
    \begin{case}{$\judgebalance{\epsilon}{d}$}
      By inversion on the derivation, we know that $d = 0$
    \end{case}

    \begin{case}{$\judgebalance{\sigma}{d}$}
      By assumption $\emptify{\sigma} = \true$, which is a contradiction. Hence this
      case is impossible. 
    \end{case}

    \begin{case}{$\judgebalance{g_1\cdot g_2}{d}$}
      By inversion, we know that $\judgebalance{g_1}{d_1}$, and
      $\judgebalance{g_2}{d_2}$, and that $d_1 + d_2 = d$.  

      By hypothesis, we know that $\emptify{g_1\cdot g_2} = \true$. 

      By definition we know that $\emptify{g_1} \land \emptify{g_2} =
      \true$. 

      Hence $\emptify{g_1} = \true$ and $\emptify{g_2} = \true$.

      By induction, $d_1 = 0$ and $d_2 = 0$. Hence $d = d_1 + d_2 = 0$. 
    \end{case}

    \begin{case}{$\judgebalance{g*}{d}$}
      By inversion, $d = 0$. 
    \end{case}

    \begin{case}{$\judgebalance{\bot}{d}$}
      Since $\emptify{\bot} = \false$, and we assume $\emptify{g} = \true$, this case is
      impossible. 
    \end{case}

    \begin{case}{$\judgebalance{g_1 \vee g_2}{d}$}
      By inversion, we know that $\judgebalance{g_1}{d}$ and $\judgebalance{g_2}{d}$. 
      
      By hypothesis, we know that $\emptify{g_1 \vee g_2} = \true$. 

      By definition, $\emptify{g_1} \vee \emptify{g_2} = \true$. 
      
      Hence either $\emptify{g_1}$ or $\emptify{g_2}$ is $\true$. 

      Suppose it is $g_i$. Then by induction $d = 0$. 

      Hence $\judgebalance{g_1 \vee g_2}{0}$. 
    \end{case}

    \begin{case}{$\judgebalance{\fix{x}{g}}{d}$}
      By inversion, $d = 0$. 
    \end{case}
  \end{caseblock}
\end{proof}

\subsection{Derivatives of Nested Words}

\subsubsection{Derivatives, Semantically}

The definition of a single-character derivative is straightforward. For 
$c \in \Sigma$, we define:

\begin{mathpar}
\semderiv{c}{L} = \comprehend{ s \in \Word }{ c\cdot s \in L}  
\end{mathpar}

\noindent We can lift to derivatives over strings $s$ in a straightforward way: 

\begin{mathpar}
  \begin{array}{lcl}
    \semderiv{\epsilon}{L} & = & L \\
    \semderiv{c \cdot s}{L} & = & \semderiv{c}{\semderiv{s}{L}} \\
  \end{array}
\end{mathpar}

\subsection{Derivatives, Syntactically}

Now, let's try to define what derivatives should be for grammar
expressions:

\begin{mathpar}
  \begin{array}{lcl}
    \deriv{\sigma}{\epsilon}        & = & \bot \\
    \deriv{\sigma}{\sigma}          & = & \epsilon \\
    \deriv{\sigma}{\sigma'}         & = & \bot \\
    \deriv{\sigma}{g_1 \cdot g_2}   & = & \deriv{\sigma}{g_1}\cdot g_2 \vee (\IfThenElse{\emptify{g_1}}{\deriv{\sigma}{g_2}}{\bot}) \\
    \deriv{\sigma}{g*}              & = & \deriv{\sigma}{g}\cdot(g*) \\
    \deriv{\sigma}{\bot}            & = & \bot \\
    \deriv{\sigma}{g_1 \vee g_2}    & = & \deriv{\sigma}{g_1} \vee \deriv{\sigma}{g_2} \\
    \deriv{\sigma}{\fix{x}{g}}      & = & \deriv{\sigma}{g}[\fix{x}{g}/x] \\
    \deriv{\sigma}{x}               & = & \mbox{(undefined)}
  \end{array}
\end{mathpar}

All of the clauses are identical to the standard derivative algorithm,
except for the last two. We do not define what the algorithm should do
when it reaches a free variable; that is, this algorithm is only
partially defined. 

The derivative of a fixed point $\fix{x}{g}$ is handled by taking the
derivative of fixed point's body, and then substituting the original
gramamtical expression for $x$ and recurring. Intuitively, a
derivative is equivalent to its unrolling, so it might seem that a
more natural thing to do is to unroll the fixed point first, and
\emph{then} take the derivative. However, this would be a
non-structural recursion, and so will complicate the theory.

However, since we are going to be considering balanced grammars, we
can exploit the fact that a one-character derivative will never to
unroll a given fixed point more than once, since every variable
occurence will be guarded. As a result, we can take the derivative,
and then perform the substitution, without changing the result (we
will prove this shortly). 

Now, the derivative of a well-typed grammar will not necessarily be
well-typed, since a subterm of the form $\lft{a}\cdot x \cdot\rgt{b}$ can
differentiated to $x\cdot\rgt{b}$, but it will be the case that any
\emph{substitution} of a derivative will also be well-typed, since
any ``bare'' variables will be replaced by well-typed terms. 

\begin{lemma}{(Existence and Well-Typedness of Derivatives)}
For any grammatical expression $g$ such that $\judgebalance{g}{d}$, 
we have that $\deriv{\sigma}{g}$ is defined and that for all 
substitutions $\gamma$ such that $\judgesubst{\Gamma'}{\gamma}{\Gamma}$, 
we have that $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g})}{d - \mathrm{sgn}(\sigma)}$
and that $\gamma(\deriv{\sigma}{g}) = \deriv{\sigma}{\gamma(g)}$. 
\end{lemma}

\begin{proof}
  This proof proceeds by induction on the derivation of $g$. 

  \begin{caseblock}
    \begin{case}{$g = \bot$ or $g = \epsilon$ or $g = \sigma'$ (where $\sigma' \not= \sigma$)}
      In each case, the derivative exists and is $\bot$, which trivially satisfies the 
      substitution condition. 
    \end{case}

    \begin{case}{$\judgebalance{\sigma}{d}$}
      In this case, the derivative is $\epsilon$, which has a balance of 0 in all 
      contexts. 

      If $\sigma \in \Sigma_i$, then $d = 0$, and $\mathrm{sgn}(\sigma) = 0$. 
      If $\sigma \in \Sigma_r$, then $d = 1$, and $\mathrm{sgn}(\sigma) = 1$. 

      Either way, $0 = d - \mathrm{sgn}(\sigma)$. 

      Again, the substitution condition is trivially satisfied, since $\epsilon$ has
      no free variables. 
    \end{case}

    \begin{case}{$\judgebalance{g_1 \vee g_2}{d}$}
      By inversion, we have $\judgebalance{g_2}{d}$ and $\judgebalance{g_2}{d}$}
      
      By induction, we have that $\deriv{\sigma}{g_1}$ and $\deriv{\sigma}{g_2}$ are
      both defined. Therefore, we know that $\deriv{\sigma}{g_1 \vee g_2} = \deriv{\sigma}{g_1} \vee 
      \deriv{\sigma}{g_2}$ is defined.

      Suppose that we have $\judgesubst{\Gamma'}{\gamma}{\Gamma}$. Then, by 
      induction we know that $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g_1})}{d}$ and 
      $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g_2})}{d}$, and furthermore 
      we know that $\gamma(\deriv{\sigma}{g_1}) = \deriv{\sigma}{\gamma(g_1)}$ and 
      $\gamma(\deriv{\sigma}{g_2}) = \deriv{\sigma}{\gamma(g_2)}$. 

      By rule \textsc{TOr}, we know that $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g_1}) \vee \gamma(\deriv{\sigma}{g_2})}{d}$. 

      This is equal to $\gamma(\deriv{\sigma}{g_1 \vee g_2})$, so we
      know $\judgebalance[\Gamma']{\gamma(g_1 \vee g_2)}{d}$.

      Furthermore, we can reason that: 
      \begin{mathpar}
        \begin{array}{lcl}
          \gamma(\deriv{\sigma}{g_1 \vee g_2})
               & = & \gamma(\deriv{\sigma}{g_1} \vee \deriv{\sigma}{g_2}) \\
               & = & \gamma(\deriv{\sigma}{g_1}) \vee \gamma(\deriv{\sigma}{g_2}) \\
               & = & \deriv{\sigma}{\gamma(g_1)} \vee \deriv{\sigma}{\gamma(g_2)} \\
               & = & \deriv{\sigma}{\gamma(g_1) \vee \gamma(g_2)} \\
               & = & \deriv{\sigma}{\gamma(g_1 \vee g_2)} \\
        \end{array}
      \end{mathpar}
    \end{case}

    \begin{case}{$g = g_1\cdot g_2$}
      By inversion, we know that $\judgebalance{g_1}{d_1}$ and 
      $\judgebalance{g_2}{d_2}$ and $d = d_1 + d_2$. 

      By induction, we know that $\deriv{\sigma}{g_1}$ and $\deriv{\sigma}{g_2}$ 
      exist. Since emptiness is defined on all well-typed grammars, it follows
      immediately that $\deriv{\sigma}{g}$ exists. 

      Now suppose that $\judgesubst{\Gamma'}{\gamma}{\Gamma}$. 

      By induction we know that $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g_1})}{d_1 - i}$ and
      that $\gamma(\deriv{\sigma}{g_1}) = \deriv{\sigma}{\gamma(g_1)}$. 
      
      By substitution, we know that $\judgebalance[\Gamma']{\gamma(g_2)}{d_2}$
        
      Therefore we know that \textsc{TCat}, we know that $\judgebalance[\Gamma']{\gamma(g_1\cdot g_2)}{d - i}$. 

      We now proceed by  case analysis on $\emptify{g_1}$. 

      \begin{itemize}
        \item If $\emptify{g_1}$ is true, then we know that $d_1 = 0$. 
        
          By induction, we know that $\judgebalance[\Gamma]{\gamma(\deriv{\sigma}{g_2})}{d - i}$, and 
          that $\deriv{\sigma}{\gamma(g_2)} = \gamma(\deriv{\sigma}{g_2})$. 
          
          Therefore we know that $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g})}{d - i}$. 

          Furthermore, we can reason that: 
          \begin{mathpar}
            \begin{array}{lcl}
              \gamma(\deriv{\sigma}{g_1\cdot g_2}) 
               & = & \gamma(\deriv{\sigma}{g_1}\cdot g_2 \vee \deriv{\sigma}{g_2}) \\
               & = & \gamma(\deriv{\sigma}{g_1}\cdot g_2) \vee \gamma(\deriv{\sigma}{g_2}) \\
               & = & \gamma(\deriv{\sigma}{g_1})\cdot \gamma(g_2) \vee \gamma(\deriv{\sigma}{g_2}) \\
               & = & \deriv{\sigma}{\gamma(g_1)}\cdot \gamma(g_2) \vee \deriv{\sigma}{\gamma(g_2)} \\
               & = & \deriv{\sigma}{\gamma(g_1)\cdot\gamma(g_2)} \\
               & = & \deriv{\sigma}{\gamma(g_1\cdot g_2)} \\
            \end{array}
          \end{mathpar}

        \item If $\emptify{g_2}$ is false, 

          We know by rule \textsc{TBot} that $\judgebalance[\Gamma']{\bot}{d - i}$. 

          Therefore we know that $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g})}{d - i}$. 
          Furthermore, we can reason that: 
          \begin{mathpar}
            \begin{array}{lcl}
              \gamma(\deriv{\sigma}{g_1\cdot g_2}) 
               & = & \gamma(\deriv{\sigma}{g_1}\cdot g_2 \vee \bot) \\
               & = & \gamma(\deriv{\sigma}{g_1}\cdot g_2) \vee \gamma(\bot}) \\
               & = & \gamma(\deriv{\sigma}{g_1})\cdot \gamma(g_2) \vee \gamma(\bot) \\
               & = & \deriv{\sigma}{\gamma(g_1)}\cdot \gamma(g_2) \vee \bot} \\
               & = & \deriv{\sigma}{\gamma(g_1)\cdot\gamma(g_2)} \\
               & = & \deriv{\sigma}{\gamma(g_1\cdot g_2)} \\
            \end{array}
          \end{mathpar}
      \end{itemize}
    \end{case}

    \begin{case}{$\judgebalance{\fix{x}{g}}{0}$}
      By inversion, we know that $\judgebalance[\Gamma, x]{g}{0}$. 
      
      So, by induction we know that $\deriv{\sigma}{g}$ is well-defined, and hence 
      $\deriv{\sigma}{\fix{x}{g}}$ is well-defined. 

      Now, suppose that we have $\judgesubst{\Gamma'}{\gamma}{\Gamma}$. Now, note that 
      by substitution, $\judgebalance[\Gamma']{\gamma(\fix{x}{g})}{0}$ holds. Hence
      $\judgesubst{\Gamma'}{\gamma_x = \gamma, [\gamma(\fix{x}{g})/x]}{\Gamma,x}$. 

      Therefore by induction hypothesis, we know that
      $\judgebalance[\Gamma']{\gamma_x(\deriv{\sigma}{g})}{-\mathrm{sgn}(\sigma)}$ and that $\deriv{\sigma}{\gamma_x(g)} = \gamma_x(\deriv{\sigma}{g})$. 

      By the definition of $\gamma_x$, substitution and the derivative, we know that $\gamma_x(\deriv{\sigma}{g}) = \gamma(\deriv{\sigma}{g}[\fix{x}{g}/x]) = \gamma(\deriv{\sigma}{\fix{x}{g}})$. 


      Therefore $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{\fix{x}{g}})}{-\mathrm{sgn}(\sigma)}$.

      Furthermore, we can reason that: 
      \begin{mathpar}
        \begin{array}{lcl}
          \gamma(\deriv{\sigma}{\fix{x}{g}})  
          & = & \gamma(\deriv{\sigma}{g}[\fix{x}{g}/x]) \\
          & = & \gamma(\deriv{\sigma}{g})[\gamma(\fix{x}{g}/x)] \\
          & = & \deriv{\sigma}{\gamma(g)}[\fix{x}{\gamma(g)}/x] \\
          & = & \deriv{\sigma}{\fix{x}{\gamma(g)}} \\
          & = & \deriv{\sigma}{\gamma(\fix{x}{g})} \\
        \end{array}
      \end{mathpar}

    \end{case}

    \begin{case}{$\judgebalance{g*}{0}$}
      By inversion, we know that $\judgebalance{g}{0}$. 

      Therefore by induction we know that $\deriv{\sigma}{g}$ exists, and so the 
      derivative $\deriv{\sigma}{g*} = \deriv{\sigma}{g}\cdot g*$ exists. 
      
      Assume that we have $\judgesubst{\Gamma'}{\gamma}{\Gamma}$. 
      
      By induction we know that $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g})}{-\mathrm{sgn}(\sigma)}$ holds,
      and that $\gamma(\deriv{\sigma}{g}) = \deriv{\sigma}{\gamma(g)}$. 

      By substitution we know that $\judgebalance[\Gamma']{(\gamma(g*)}{0}$ holds. 

      By rule \textsc{TCat}, we know that $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g})\cdot\gamma(g*)}{-\mathrm{sgn}(\sigma)}$ holds. 

      Therefore $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g}\cdot(g*))}{-\mathrm{sgn}(\sigma)}$ holds, and
      so $\judgebalance[\Gamma']{\gamma(\deriv{\sigma}{g*})}{-\mathrm{sgn}(\sigma)}$ holds. 

      Furthermore, we can reason that: 
      \begin{mathpar}
        \begin{array}{lcl}
          \gamma(\deriv{\sigma}{g*})  
          & = & \gamma(\deriv{\sigma}{g}\cdot(g*)) \\
          & = & \gamma(\deriv{\sigma}{g})\cdot\gamma(g*) \\
          & = & \deriv{\sigma}{\gamma(g)}\cdot(\gamma(g))* \\
          & = & \deriv{\sigma}{(\gamma(g))*} \\
          & = & \deriv{\sigma}{\gamma(g*)} \\
        \end{array}
      \end{mathpar}
    \end{case}

    \begin{case}{$\judgebalance{\lft{a}\cdot x \cdot\rgt{b}}{0}$}
      If $\sigma = \lft{a}$, then $\deriv{\sigma}{\lft{a}\cdot x \cdot\rgt{b}} = x \cdot \rgt{b}$, and
      if it is not, then the derivative is $\bot$. Either way, the derivative exists. 

      Now suppose we have $\judgesubst{\Gamma'}{\gamma}{\Gamma}$. 

      If the derivative is $\bot$, then the conclusion is immediate. 

      Otherwise, we know that $\judgebalance[\Gamma']{\gamma(x)}{0}$, and so by rule 
      \textsc{TCat}, we know that $\judgebalance[\Gamma']{\gamma(x)\cdot \rgt{b}}{+1}$. 

      Furthermore, it is immediate that $\gamma(\deriv{\sigma}{\lft{a}\cdot x\cdot\rgt{b}}) = \gamma(x \cdot \rgt{b})$
    \end{case}
  \end{caseblock}
\end{proof}







Now, let's show that syntactic and semantic derivatives coincide. 

\begin{prop}{(Syntactic and Semantic Derivatives Coincide)}
For any closed, well-typed $g$ and character $\sigma$, we have that
$\interp{\deriv{\sigma}{g}} = \semderiv{\sigma}{\interp{g}}$.
\end{prop}

\begin{proof}
  We proceed by induction of $g$: 

  \begin{caseblock}
    \begin{case}{$\sigma'$}
      There are two possibilities, depending on whether or not $\sigma = \sigma'$: 
      \begin{itemize}
        \item If $\sigma = \sigma'$, then $\interp{\deriv{\sigma}{\sigma}} = \interp{\epsilon} = \setof{\epsilon}$

          Furthermore, $\interp{\sigma} = \setof{\sigma}$, and $\semderiv{\sigma}{\setof{\sigma}} = \setof{\epsilon}$
        \item If $\sigma \not= \sigma'$, then $\interp{\deriv{\sigma}{\sigma'}} = \interp{\bot} = \emptyset$
          
          Furthermore, $\interp{\sigma'} = \setof{\sigma'}$, and $\semderiv{\sigma}{\setof{\sigma'}} = \emptyset$
      \end{itemize}
    \end{case}

    \begin{case}{$\epsilon$}
      $\interp{\deriv{\sigma}{\epsilon}} = \interp{\bot} = \emptyset = \semderiv{\sigma}{\setof{\epsilon}} = \semderiv{\sigma}{\interp{\epsilon}}$
    \end{case}

    \begin{case}{$g_1\cdot g_2$}
      We need to show that $\interp{\deriv{\sigma}{g_1\cdot g_2}} = \semderiv{\sigma}{\interp{g_1\cdot g_2}}$. 
      \begin{enumerate}
        \item By induction, we know that $\interp{\deriv{\sigma}{g_1}} = \semderiv{\sigma}{\interp{g_1}}$
        \item By induction, we know that $\interp{\deriv{\sigma}{g_2}} = \semderiv{\sigma}{\interp{g_2}}$
        \item Now we need to show that for all $s$, $s \in \interp{\deriv{\sigma}{g_1\cdot g_2}}$ if and 
          only if $s \in \semderiv{\sigma}{\interp{g_1\cdot g_2}}$. 
          \begin{itemize}
          \item The $\Leftarrow$ direction: 
            \begin{enumerate}
              \item Suppose $s \in \semderiv{\sigma}{\interp{g_1\cdot g_2}}$. 
              \item Then there exist $s_1$ and $s_2$ such that $\sigma\cdot s = s_1\cdot s_2$ and 
                $s_1 \in \interp{g_1}$ and $s_2 \in \interp{g_2}$. 
              \item Now, $s_1$ has either 0 or more elements. 
                \begin{itemize}
                  \item Suppose $s_1$ has length $0$. 
                    \begin{enumerate}
                      \item Then $s_1$ is the empty string, so $\epsilon \in \interp{g_1}$ and 
                            $s_2 = \sigma \cdot s$
                      \item From the emptiness lemma,  $\emptify{g_1} = \epsilon$ 
                      \item From the induction hypothesis, $s \in \interp{\deriv{\sigma}{g_2}}$ 
                      \item Therefore $s \in \interp{\emptify{g_1}\cdot\deriv{\sigma}{g_2}}$
                      \item Therefore $s \in \interp{\deriv{\sigma}{g_1}\cdot g_2 \vee \emptify{g_1}\cdot\deriv{\sigma}{g_2}}$
                  \end{enumerate}
                 \item Suppose $s_1$ has length $n \geq 1$ 
                   \begin{enumerate}
                     \item Then there exists $s'_1$ such that $s = s'_1 \cdot s_2$ and $s_1 = \sigma \cdot s'_1$. 
                     \item Therefore $s'_1 \in \semderiv{\sigma}{\interp{g_1}}$
                     \item By induction hypothesis $s'_1 \in \interp{\deriv{\sigma}{g_1}}$
                     \item Therefore $s = s'_1 \cdot s_2$ is in $\interp{\deriv{\sigma}{g_1}\cdot g_2}$
                     \item Therefore $s \in \interp{\deriv{\sigma}{g_1}\cdot g_2 \vee \emptify{g_1}\cdot\deriv{\sigma}{g_2}}$
                   \end{enumerate}
                \end{itemize}
            \end{enumerate}
          \item The $\Rightarrow$ direction: 
            \begin{enumerate}
              \item Suppose $s \in \interp{\deriv{\sigma}{g_1\cdot g_2}}$
              \item Therefore $s \in \interp{\deriv{\sigma}{g_1}\cdot g_2 \vee \emptify{g_1}\cdot\deriv{\sigma}{g_2}}$
              \item Therefore either $s \in \interp{\deriv{\sigma}{g_1}\cdot g_2}$ or 
                    $s \in \interp{\emptify{g_1}\cdot\deriv{\sigma}{g_2} }$
                \begin{itemize}
                  \item Suppose $s \in \interp{\deriv{\sigma}{g_1}\cdot g_2}$ 
                    \begin{enumerate}
                      \item Therefore there exist $s_1, s_2$ such that $s = s_1 \cdot s_2$ and 
                        $s_1 \in \interp{\deriv{\sigma}{g_1}}$ and $s_2 \in \interp{g_2}$
                      \item By induction hypothesis $s_1 \in \semderiv{\sigma}{\interp{g_1}}$
                      \item Therefore $\sigma \cdot s_1 \in \interp{g_1}$
                      \item Therefore $\sigma \cdot s_1 \cdot s_2 \in \interp{g_1 \cdot g_2}$
                      \item Therefore $s_1 \cdot s_2 \in \semderiv{\sigma}{g_1 \cdot g_2}$
                    \end{enumerate}
                  \item Suppose $s \in \interp{\emptify{g_1}\cdot\deriv{\sigma}{g_2} }$

                \end{itemize}
            \end{enumerate}
          \end{itemize}
      \end{enumerate}
    \end{case}
  \end{caseblock}
\end{proof}


\begin{prop}{(Syntactic Derivatives of Strings)}
For any string $s$, and grammatical expression $g$ the following propositions hold:
\begin{enumerate}
\item $\deriv{s}{g_1 \vee g_2} \simeq \deriv{s}{g_1} \vee \deriv{s}{g_2}$
\item $\deriv{s}{g_1 \cdot g_2} \simeq \deriv{s}{g_1}\cdot g_2 \vee \bigvee_{\comprehend{s_1, s_2}{s = s_1\cdot s_2}} \emptify{\deriv{s_1}{g_1}}\cdot \deriv{s_2}{g_2}$
% \item $\deriv{s}{g*} \simeq \left(\bigvee_{\comprehend{(s_1, \ldots, s_k)}{s = s_1 \cdot \ldots s_{k+1} \land \forall j \leq k.\; |s_j} > 0}} \emptify{\deriv{s_1}{g}}\cdot\ldots\cdot\emptify{\deriv{s_k}{g}}\cdot\deriv{s_{k+1}}{g}\right)\cdot (g*)$
\end{enumerate}
\end{prop}

\begin{proof}
In each case, we proceed by induction on $s$.   
\begin{enumerate}
\item $\deriv{s}{g_1 \vee g_2} \simeq \deriv{s}{g_1} \vee \deriv{s}{g_2}$
  \begin{caseblock}
    \begin{case}{$s = \epsilon$}
      $\deriv{\epsilon}{g_1 \vee g_2} \simeq g_1 \vee g_2 \simeq\deriv{\epsilon}{g_1} \vee \deriv{\epsilon}{g_2}$
    \end{case}

    \begin{case}{$s = \sigma\cdot s'$}
      \begin{mathpar}
        \begin{array}{lcll}
          \mbox{By definition,} & \deriv{\sigma\cdot s'}{g_1 \vee g_2} & = & 
             \deriv{s'}{\deriv{\sigma}{g_1 \vee g_2}} \\
          \mbox{By definition} & & = & 
            \deriv{s'}{\deriv{\sigma}{g_1} \vee \deriv{\sigma}{g_2}} \\
          \mbox{By induction}  & & = & 
             \deriv{\sigma\cdot s'}{g_1} \vee \deriv{\sigma\cdot s'}{g_2} \\
        \end{array}
      \end{mathpar}
    \end{case}
  \end{caseblock}

\item $\deriv{s}{g_1 \cdot g_2} \simeq \deriv{s}{g_1}\cdot g_2 \vee \bigvee_{\comprehend{s_1, s_2}{s = s_1\cdot s_2}} \emptify{\deriv{s_1}{g_1}}\cdot \deriv{s_2}{g_2}$
  \begin{caseblock}
    \begin{case}{$s = \epsilon$}
      \begin{mathpar}
        \begin{array}{llcl}
          \mbox{By definition} & \deriv{\epsilon}{g_1 \cdot g_2} & = & 
             g_1 \cdot g_2 \\
          \mbox{By equation} & & \simeq & 
             g_1 \cdot g_2 \vee \emptify{g_1}\cdot g_2 \\
          \mbox{By equation} & & \simeq & 
             g_1 \cdot g_2 \vee \emptify{g_1}\cdot \deriv{\epsilon}{g_2} \\
        \end{array}
      \end{mathpar}
    \end{case}

    \begin{case}{$s = \sigma \cdot s'$}
      \begin{mathpar}
        \begin{array}{llcl}
          \mbox{By def} & \deriv{\sigma\cdot s'}{g_1 \cdot g_2} & = & 
             \deriv{s'}{\deriv{\sigma}{g_1\cdot g_2}} \\
          \mbox{By def} & & = & 
              \deriv{s'}{\deriv{\sigma}{g_1}\cdot g_2 \vee \emptify{g_1}\deriv{\sigma}{g_2}} \\
          \mbox{By def} & & = & 
              \deriv{s'}{\deriv{\sigma}{g_1}\cdot g_2} \vee 
              \deriv{s'}{\emptify{g_1}\deriv{\sigma}{g_2}} \\
          \mbox{By IH} & & \simeq & 
              \deriv{\sigma\cdot s'}{g_1}\cdot g_2 \vee \bigvee_{\comprehend{s_1, s_2}{s' = s_1\cdot s_2}} \emptify{\deriv{\sigma\cdot s_1}{g_1}}\cdot \deriv{s_2}{g_2} \;\vee \\
                       & & & 
               \deriv{s'}{\emptify{g_1}}\cdot \deriv{\sigma}{g_2} \vee \bigvee_{\comprehend{s_1, s_2}{s' = s_1\cdot s_2}} \emptify{\deriv{s_1}{\emptify{g_1}}}\cdot \deriv{s_2}{\deriv{\sigma}{g_2}} \\
          \mbox{Semantics} & & \simeq & 
              \deriv{\sigma\cdot s'}{g_1}\cdot \deriv{\sigma}{g_2} \vee \bigvee_{\comprehend{s_1, s_2}{s' = s_1\cdot s_2}} \emptify{\deriv{\sigma\cdot s_1}{g_1}}\cdot \deriv{s_2}{\deriv{\sigma}{g_2}} \\
                       & & & 
              \vee \emptify{g_1}\cdot\deriv{s}{g_2} \\
           \mbox{Simplify} & & \simeq & 
           \deriv{s}{g_1}\cdot g_2 \vee \bigvee_{\comprehend{s_1, s_2}{s = s_1\cdot s_2}} \emptify{\deriv{s_1}{g_1}}\cdot \deriv{s_2}{g_2}
        \end{array}
      \end{mathpar}
    \end{case}
  \end{caseblock}

\item $\deriv{s}{g*} \simeq \left(\bigvee_{\comprehend{(s_0, \ldots, s_k)}{s = s_0 \cdot \ldots s_{k+1}}} \emptify{\deriv{s_0}{g}}\cdot\ldots\cdot\emptify{\deriv{s_k}{g}}\cdot\deriv{s_{k+1}}{g}\right)\cdot (g*)$

\end{enumerate}
\end{proof}


\section{Nondeterministic Brzozowski Derivatives}

Now, our definition is sound, in the sense that it means the right
thing. Unfortunately, it won't give us a finite set of derivatives. 
For example,  consider the grammar $i := \epsilon \vee \lft{a} i \rgt{b}$. 
When we  differentiate with respect to $\lft{a}$, the result is equivalent to 
\begin{mathpar}
(\epsilon \vee \lft{a} i \rgt{b}) \cdot \rgt{b}
\end{mathpar}

\noindent When we differentiate this again, we get
\begin{mathpar}
(\epsilon \vee \lft{a} i \rgt{b}) \cdot \rgt{b} \cdot \rgt{b}  
\end{mathpar}

\noindent and so on for arbitrary $n$-fold derivatives.  Of course, this
shouldn't be terribly surprising --- we're interpreting expressions as states,
and there's no finite state machine that can recognize this language! 

So what we need to do is find some generalization of the notion of derivative,
from which we some kind of stack machine will fall out in the same way that 
finite-state automata fall out of derivatives of regular expressions.  

To do this, we'll proceed in two steps. First, we'll give a 
non-deterministic version of the Brzozowski derivative algorithm, and
then show how to determinize it. 

\begin{definition}{(Finite Base)}
We say a grammatical expression $g$ is derived from $B$, when $B$ is a
finite set of grammatical expressions, and $g$ is equivalent to a sum of
concatenations of elements of $B$. That is, $g$ should be generated (up to $\simeq$)
via the following grammar:
\begin{mathpar}
  \begin{array}{lcl}
    t & ::= & \sigma \bnfalt \epsilon \bnfalt t \cdot t' \bnfalt \bot \bnfalt t \vee t' \bnfalt b \in B
  \end{array}
\end{mathpar}

We say a grammatical expression $g$ is based in $B$, when $g$ and all 
of its derivatives are based in $B$. 
\end{definition}

The intuition behind this definition is that it is a way of
distinguishing the pieces of a grammatical expression that don't
require recursion from those that do --- observe that $g*$ and
$\fix{x}{g}$ do not occur in the grammar $t$, and hence must 
come from the basis $B$. 

\begin{prop}{(Closure of Finite Basis)}
Suppose that $g$ and $g'$ are grammatical expressions with a free
variables in $\Gamma$. Now, suppose that there is a set $G$, such that
for any $\gamma$ which is finitely based in $X$, that $\gamma(g)$ and
$\gamma(g')$ are finitely based in $G \cup X$.  Then we know that
$\gamma(g[g'/x])$ is finitely based in $G \cup X$.
\end{prop}

\begin{proof}
We proceed by induction on $g$. We will suppose $s$ is a string we 
take a derivative with respect to. 
\begin{caseblock}
  \begin{case}{$g \in \setof{\bot, \epsilon, \sigma}$}
    These cases are all trivial. 
  \end{case}

  \begin{case}{$g$ is $(g')*$, $g_1\cdot g_2$ or $g_1 \vee g_2$}
    These cases all follow from the structure of the syntactic derivative
    for strings. 
  \end{case}

  \begin{case}{$g = \lft{a}y\rgt{b}$}
    The only interesting possibility is if $y = x$. Then the substitution 
    gives us $\lft{a}g'\rgt{b}$, which obviously has the same finite basis as $g'$. 
  \end{case}

  \begin{case}{$g = \fix{y}{g''}$}
    This is where we find out if the induction hypothesis is strong enough!
    \begin{itemize}
      \item We have $G$, $X$, and $\gamma$ finitely based in $X$, and $g'$ finitely
        based in $G \cup X$. 
      \item By inversion we have $g''$ in a context $\Gamma' = \Gamma, y$. 
      \item By induction we have for all $g'$, $G$, $X$, and $\gamma'$ for $\Gamma'$ finitely
        based in $X$, that if $\gamma'(g'')$ and $\gamma'(g')$ are finitely based in $G \cup X$,
        then $\gamma'(g''[g'/x])$ is finitely based in $G \cup X$. 
      \item In the induction hypothesis, take $\gamma' = \gamma, [y \mapsto \fix{y}{g''}]$ and 
        $X$ to be $G \cup X$. Since we know that $\fix{y}{g''}$ has basis $G \cup X$, and since
        $\gamma$ has basis $X$, it follows that $\gamma'(g'')$ has basis $G \cup X$. Furthermore, 
        since $y \not\in \mathrm{FV}(g')$, it follows that $\gamma'(g') = \gamma''(g')$, and 
        so $\gamma'(g')$ is finitely based in $G \cup X$. 
      \item Therefore $\gamma'(g''[g'/x])$ is finitely based in $G \cup X$. 
      \item Since $\gamma'(g''[g'/x]) \simeq\gamma(\fix{y}{g''[g'/x]}) \simeq \gamma(g[g'/x])$, 
        this case follows.         
    \end{itemize}
  \end{case}
\end{caseblock}
\end{proof}



\begin{prop}{(The Set of Derivatives Is Finitely Based)}
For any grammatical expression $g$ with free variables $\Gamma$, there
is a finite set $G$ such that every for every substitution $\gamma$ all of 
whose derivatives are finitely based in $X$, the derivative $D_s(\gamma(g))$ 
is finitely based in $G \cup X$.  
\end{prop}

\begin{proof}
\begin{caseblock}
  \begin{case}{$g = \epsilon$}
    Let $G = \emptyset$. If $s$ is the empty string, 
    then $D_\epsilon(\epsilon) = \epsilon$. If it is nonempty, then $D_{c\cdot s'}(\epsilon) = \bot$. 
  \end{case}

  \begin{case}{$g = \sigma$}
    Let $G = \setof{\sigma}$. If $s$ is empty, the derivative is $\sigma$. 
    If $s$ is $\sigma$, the derivative is $\epsilon$. Otherwise, it is $\bot$. 
  \end{case}

  \begin{case}{$g = \bot$}
    Let $G = \emptyset$. All derivatives of $\bot$ are $\bot$. 
  \end{case}

  \begin{case}{$g = g_1 \vee g_2$}
    Let $G_1$ and $G_2$ be the basis sets of $g_1$ and $g_2$. Then, we know 
    that $\deriv{s}{\gamma(g_1 \vee g_2)} = \deriv{s}{\gamma(g_1)} \vee \deriv{s}{\gamma(g_2)}$. Since
    $\deriv{s}{g_1}$ is finitely based in $G_1 \cup X$ and $\deriv{s}{g_2}$ is finitely based in $G_2 \cup X$, 
    it follows that $\deriv{s}{g_1} \vee \deriv{s}{g_2}$ is finitely based in $G \cup X$. 
  \end{case}

  \begin{case}{$g = \fix{x}{g'}$}
    Let $G'$ be the basis set of $g'$. Now, take $G$ to be $G \cup \setof{\fix{x}{g'}}$. 
    To show that this is a basis of $\fix{x}{g'(x)}$ for arbitrary $s$ of length $n$, unroll
    the fixed point $n$ times to get $g'' = (g')^n(\fix{x}{g'(x)}$, which we know has the same basis. 
    Now every occurence of $\fix{x}{g}$ in the new expression will have $n$ occurences of some 
    $\lft{a}$ in front of it, and so the taking the derivative with respect to $s$ will never 
    unroll this loop. Therefore, [FIXME]
  \end{case}
\end{caseblock}
\end{proof}

In fact, it's not enough to know that a grammatical expression is
finitely based to ensure that it has a


\end{document}
